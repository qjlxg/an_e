import pandas as pd
import requests
from bs4 import BeautifulSoup
import os
import time
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- ä¾èµ–çš„åº“: requests, pandas, beautifulsoup4 ---
OUTPUT_FILE = 'fund_details.csv'
INPUT_FILE = 'result_z.txt'
# ä¿æŒè¾ƒä½çš„å¹¶å‘æ•°ï¼Œé¿å…è¢«çˆ¬è™«ç›®æ ‡ç½‘ç«™å°é”
MAX_WORKERS = 5 

# ğŸš¨ ä¿®æ­£åçš„ URL ç»“æ„ï¼šæŒ‡å‘åŸºé‡‘æ¡£æ¡ˆ (F10) çš„åŸºæœ¬æ¦‚å†µé¡µ
BASE_URL = "https://fundf10.eastmoney.com/jbgk_{fund_code}.html"


def fetch_fund_info(fund_code):
    """
    çˆ¬å–åŸºé‡‘è¯¦æƒ…é¡µé¢ï¼Œä½¿ç”¨ BeautifulSoup æå–å®Œæ•´çš„åŸºé‡‘åŸºæœ¬ä¿¡æ¯ã€‚
    é‡‡ç”¨æ–°çš„è§£æç­–ç•¥ï¼šç›´æ¥ä»â€œåŸºæœ¬æ¦‚å†µâ€è¡¨æ ¼ä¸­æå–æ‰€æœ‰ä¿¡æ¯ã€‚
    """
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] æ­£åœ¨æŸ¥è¯¢ä»£ç : {fund_code}")
    
    url = BASE_URL.format(fund_code=fund_code)
    
    # æ¨¡æ‹Ÿ HTTP è¯·æ±‚å¤´
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    }

    # é»˜è®¤å€¼
    details = {
        'åŸºé‡‘ä»£ç ': fund_code,
        'åŸºé‡‘åç§°': 'N/A',
        'åŸºé‡‘ç®¡ç†äºº': 'N/A',
        'åŸºé‡‘ç»ç†': 'N/A',
        'æˆç«‹æ—¥æœŸ': 'N/A',
        'åŸºé‡‘æ‰˜ç®¡äºº': 'N/A',
        'æ›´æ–°æ—¶é—´': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }

    try:
        # å¢åŠ è¶…æ—¶æ—¶é—´åˆ° 20 ç§’ï¼Œæé«˜è¯·æ±‚ç¨³å®šæ€§
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status() # æ£€æŸ¥ HTTP çŠ¶æ€ç 
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # --- 1. æå–åŸºæœ¬æ¦‚å†µè¡¨æ ¼æ•°æ® (æœ€è¯¦ç»†å¯é çš„æ¥æº) ---
        # å®šä½åˆ°â€œåŸºæœ¬æ¦‚å†µâ€ä¸‹çš„ä¿¡æ¯è¡¨æ ¼
        info_table = soup.select_one('div.boxitem table.info')
        
        if info_table:
            info_map = {}
            # æå–è¡¨æ ¼ä¸­æ‰€æœ‰ key-value å¯¹
            cells = info_table.find_all('td')
            
            # éå†å•å…ƒæ ¼ï¼ŒæŒ‰ä¸¤ä¸¤ä¸€ç»„ï¼ˆkey/valueï¼‰æå–
            i = 0
            while i < len(cells):
                key_cell = cells[i]
                key = key_cell.text.strip()
                
                # æ£€æŸ¥ä¸‹ä¸€ä¸ªå•å…ƒæ ¼æ˜¯å¦å­˜åœ¨
                if i + 1 < len(cells):
                    value_cell = cells[i+1]
                    value = value_cell.text.strip()
                    info_map[key] = value

                    # å¦‚æœ value å•å…ƒæ ¼æœ‰ colspan="3" å±æ€§ï¼Œè¯´æ˜å®ƒè·¨è¶Šäº†ä¸‰åˆ—ï¼ˆå äº† key å’Œ value çš„ä½ç½®ï¼‰
                    # åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä¸‹ä¸€æ¬¡è¿­ä»£åº”è¯¥è·³è¿‡ä¸‰ä¸ªå•å…ƒæ ¼ï¼Œå³ i += 4
                    # å®é™…è§‚å¯Ÿä¸­ï¼Œè¡¨æ ¼æ˜¯ä¸¤åˆ—ç»“æ„ï¼Œæ‰€ä»¥æˆ‘ä»¬æ€»æ˜¯è·³è¿‡ i += 2
                    i += 2 
                else:
                    break
            
            # ä½¿ç”¨æå–çš„ map å¡«å…… details
            details['åŸºé‡‘åç§°'] = info_map.get('åŸºé‡‘å…¨ç§°', details['åŸºé‡‘åç§°'])
            details['åŸºé‡‘ç®¡ç†äºº'] = info_map.get('åŸºé‡‘ç®¡ç†äºº', details['åŸºé‡‘ç®¡ç†äºº'])
            details['åŸºé‡‘æ‰˜ç®¡äºº'] = info_map.get('åŸºé‡‘æ‰˜ç®¡äºº', details['åŸºé‡‘æ‰˜ç®¡äºº'])
            
            # æˆç«‹æ—¥æœŸå’Œè§„æ¨¡åœ¨ä¸€èµ·ï¼Œéœ€è¦åˆ†å‰²å¹¶æ¸…æ´—
            if 'æˆç«‹æ—¥æœŸ/è§„æ¨¡' in info_map:
                # ç¤ºä¾‹: 2021å¹´12æœˆ02æ—¥ / 1.182äº¿ä»½
                date_str = info_map['æˆç«‹æ—¥æœŸ/è§„æ¨¡'].split('/')[0].strip()
                # æ¸…æ´—æ ¼å¼ä¸º YYYY-MM-DD
                details['æˆç«‹æ—¥æœŸ'] = date_str.replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '').strip('-').strip()
            
            # åŸºé‡‘ç»ç†å¯èƒ½åœ¨ 'åŸºé‡‘ç»ç†äºº' å­—æ®µä¸­
            details['åŸºé‡‘ç»ç†'] = info_map.get('åŸºé‡‘ç»ç†äºº', details['åŸºé‡‘ç»ç†'])
        
        
        # --- 2. è¡¥å……/è¦†ç›– åŸºé‡‘ç»ç† (ä»å¿«é€Ÿæ¦‚è§ˆä¸­è·å–ï¼Œé˜²æ­¢è¡¨æ ¼ç¼ºå¤±) ---
        # æŸ¥æ‰¾å¿«é€Ÿæ¦‚è§ˆåŒºåŸŸçš„åŸºé‡‘ç»ç† a æ ‡ç­¾ (æ›´ç›´æ¥)
        manager_tag = soup.select_one('.bs_gl label:has(a[href*="manager"]) a')
        if manager_tag:
            details['åŸºé‡‘ç»ç†'] = manager_tag.text.strip()


        # --- 3. è¡¥å…… åŸºé‡‘åç§° (å¦‚æœè¡¨æ ¼ä¸­æ²¡æœ‰åŸºé‡‘å…¨ç§°ï¼Œåˆ™ä»é¡µé¢å¤§æ ‡é¢˜è·å–) ---
        if details['åŸºé‡‘åç§°'] == 'N/A' or details['åŸºé‡‘åç§°'] == '':
            title_tag = soup.select_one('.basic-new .col-left .title a')
            if title_tag:
                full_name_text = title_tag.text.strip()
                # æ ¼å¼å¦‚: æ±‡æ·»å¯Œä¸­è¯èŠ¯ç‰‡äº§ä¸šæŒ‡æ•°å¢å¼ºå‘èµ·å¼... (014194)
                details['åŸºé‡‘åç§°'] = full_name_text.split('(')[0].strip()

        
        time.sleep(0.2) # ä¿æŒçŸ­å»¶è¿Ÿï¼Œé™ä½çˆ¬è™«é¢‘ç‡
        return details
        
    except requests.exceptions.RequestException as e:
        print(f"åŸºé‡‘ä»£ç  {fund_code} è¯·æ±‚å¤±è´¥: {e}")
        time.sleep(1) 
        # å‘ç”Ÿç½‘ç»œé”™è¯¯æ—¶ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
        return {
            'åŸºé‡‘ä»£ç ': fund_code,
            'åŸºé‡‘åç§°': 'ç½‘ç»œè¯·æ±‚å¤±è´¥',
            'åŸºé‡‘ç®¡ç†äºº': 'N/A',
            'åŸºé‡‘ç»ç†': 'N/A',
            'æˆç«‹æ—¥æœŸ': 'N/A',
            'åŸºé‡‘æ‰˜ç®¡äºº': 'N/A',
            'æ›´æ–°æ—¶é—´': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }


def main():
    
    # 1. è¯»å–åŸºé‡‘ä»£ç 
    print(f"å°è¯•è¯»å–æ–‡ä»¶: {INPUT_FILE}")
    try:
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            fund_codes = [line.strip() for line in f if line.strip()]
        
        fund_codes = list(dict.fromkeys(fund_codes))
        print(f"æˆåŠŸè¯»å– {len(fund_codes)} ä¸ªåŸºé‡‘ä»£ç ã€‚")
        
    except FileNotFoundError:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {INPUT_FILE}")
        return
    
    # 2. æ‰¹é‡å¹¶è¡Œè·å–åŸºé‡‘ä¿¡æ¯
    all_fund_details = []
    print(f"å¼€å§‹å¹¶è¡Œè·å–åŸºé‡‘åŸºæœ¬ä¿¡æ¯ï¼Œæœ€å¤§çº¿ç¨‹æ•°: {MAX_WORKERS}...")
    
    if 'pd' not in globals():
        print("è‡´å‘½é”™è¯¯ï¼šç¼ºå°‘ pandas åº“ã€‚è¯·æ£€æŸ¥ä¾èµ–å®‰è£…æ­¥éª¤ã€‚")
        return

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_code = {executor.submit(fetch_fund_info, code): code for code in fund_codes}
        
        for future in as_completed(future_to_code):
            try:
                data = future.result()
                all_fund_details.append(data)
            except Exception as exc:
                print(f'ä¸€ä¸ªçº¿ç¨‹æ‰§è¡Œå‘ç”Ÿé”™è¯¯: {exc}')

    print("æ‰€æœ‰åŸºé‡‘ä¿¡æ¯è·å–å’Œå¤„ç†å®Œæˆã€‚")
    
    # 3. è½¬æ¢ä¸º DataFrame å¹¶ä¿å­˜ä¸º CSV
    if not all_fund_details:
        print("æ²¡æœ‰è·å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡æ–‡ä»¶ä¿å­˜ã€‚")
        return

    df = pd.DataFrame(all_fund_details)
    df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')
        
    print(f"æ‰€æœ‰åŸºé‡‘ä¿¡æ¯å·²ä¿å­˜åˆ° CSV æ–‡ä»¶: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
