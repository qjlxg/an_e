name: ç»ç†

on:
  # å…è®¸æ‰‹åŠ¨è¿è¡Œ
  workflow_dispatch:
  # å½“è„šæœ¬ã€é…ç½®æ–‡ä»¶æˆ–å·¥ä½œæµæœ¬èº«å˜åŠ¨æ—¶è‡ªåŠ¨è¿è¡Œ
  push:
    paths:
      - 'scrape_fund_data.py'
      - '.github/workflows/update_data.yml'
      - 'Cç±».txt'

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ŒæŒ‡å®šæ—¶åŒºä¸ºä¸Šæµ·æ—¶åŒº
env:
  TZ: Asia/Shanghai

jobs:
  scrape_and_push:
    runs-on: ubuntu-latest
    
    steps:
      - name: æ£€å‡ºä»£ç 
        uses: actions/checkout@v4
        with:
          # å¿…é¡»æ£€å‡ºï¼Œæ‰èƒ½å°†ç”Ÿæˆçš„æ–°æ–‡ä»¶æ¨é€å›ä»“åº“
          fetch-depth: 0 
          
      - name: è®¾ç½®Pythonç¯å¢ƒ
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: å®‰è£…ä¾èµ– (requests, beautifulsoup4, pandas)
        # å¢åŠ äº† pandas ä¾èµ–
        run: pip install requests beautifulsoup4 pandas

      - name: è¿è¡Œæ•°æ®æŠ“å–è„šæœ¬ (å¹¶è¡Œ)
        # è„šæœ¬å°†ç”Ÿæˆ 'å¹´/æœˆ/æ€»è¡¨_YYYYMMDD_HHMMSS.csv' æ ¼å¼çš„æ–‡ä»¶
        run: python scrape_fund_data.py
        
      - name: é…ç½® Git ç”¨æˆ·ä¿¡æ¯
        run: |
          # ä½¿ç”¨ GitHub Actions çš„é»˜è®¤ bot èº«ä»½è¿›è¡Œæäº¤
          git config user.name 'github-actions[bot]'
          git config user.email 'github-actions[bot]@users.noreply.github.com'

      - name: æ¨é€æ–°ç”Ÿæˆçš„æ•°æ®åˆ°ä»“åº“
        run: |
          # æ·»åŠ æ‰€æœ‰æ–°å¢æˆ–ä¿®æ”¹çš„æ–‡ä»¶ï¼ˆåŒ…æ‹¬æ–°çš„ å¹´/æœˆ ç›®å½•å’Œcsvæ–‡ä»¶ï¼‰
          git add .
          
          # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶æ›´æ”¹éœ€è¦æäº¤
          # '??' è¡¨ç¤ºæœªè·Ÿè¸ªçš„æ–‡ä»¶ (æ–°ç”Ÿæˆçš„csv)ï¼Œ'M' è¡¨ç¤ºå·²ä¿®æ”¹çš„æ–‡ä»¶
          if git status --porcelain | grep -q '??' || git status --porcelain | grep -q 'M'; then
            # ä½¿ç”¨ä¸Šæµ·æ—¶åŒºçš„æ—¶é—´ç”Ÿæˆ commit ä¿¡æ¯
            COMMIT_TIME=$(TZ=Asia/Shanghai date "+%Y-%m-%d %H:%M:%S")
            git commit -m "ğŸ¤– Auto: å¹¶è¡Œæ›´æ–°åŸºé‡‘æ•°æ®æ€»è¡¨ - ${COMMIT_TIME} (Shanghai)"
            git push
          else
            echo "æ²¡æœ‰æ–°çš„æ•°æ®æ–‡ä»¶ç”Ÿæˆæˆ–æ–‡ä»¶å†…å®¹æ²¡æœ‰å˜åŒ–ï¼Œè·³è¿‡æ¨é€ã€‚"
          fi
