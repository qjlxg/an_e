# index_analysis.py - ç‹¬ç«‹è·Ÿè¸ªæ ‡çš„é‡åŒ–åˆ†æè„šæœ¬
import akshare as ak
import pandas as pd
import numpy as np
import talib
import re
import time
import random
# å¯¼å…¥ requests å¼‚å¸¸
from requests.exceptions import ConnectionError, Timeout
# å¯¼å…¥åº•å±‚ http å®¢æˆ·ç«¯å¼‚å¸¸ï¼Œè§£å†³ RemoteDisconnected é”™è¯¯
import http.client

# --- é…ç½® ---
# è¡¥å……åçš„æŒ‡æ•°åç§°åˆ° AkShare ä»£ç çš„æ˜ å°„
INDEX_MAP = {
    'æ²ªæ·±300æŒ‡æ•°': '000300',
    'ä¸­è¯500æŒ‡æ•°': '000905',
    'ä¸­è¯800æŒ‡æ•°': '000906',
    'åˆ›ä¸šæ¿æŒ‡æ•°': '399006',
    'ä¸Šè¯æŒ‡æ•°': '000001',
    'æ’ç”ŸæŒ‡æ•°': 'HSI',
    'ç§‘åˆ›æ¿50æˆä»½æŒ‡æ•°': '000688',
    'ä¸­è¯æ™ºèƒ½æ±½è½¦ä¸»é¢˜æŒ‡æ•°': '399976',
    'ä¸­è¯ç”µå­æŒ‡æ•°': '000807',
    'ä¸­è¯å†›å·¥æŒ‡æ•°': '399967',
    'ä¸­è¯æ–°èƒ½æºæ±½è½¦æŒ‡æ•°': '399808',
    'ä¸­è¯åŒ»è¯å«ç”ŸæŒ‡æ•°': '000933',
    'ä¸­è¯å…‰ä¼äº§ä¸šæŒ‡æ•°': '399989',  # å·²éªŒè¯å¹¶ä¿®æ­£ï¼šåŸ000807æ˜¯ä¸­è¯ç”µå­ï¼Œå…‰ä¼äº§ä¸šæŒ‡æ•°åº”ä¸º399989
    'ä¸­è¯äººå·¥æ™ºèƒ½ä¸»é¢˜æŒ‡æ•°': '000885',  # å·²éªŒè¯å¹¶ä¿®æ­£ï¼šåŸ000688æ˜¯ç§‘åˆ›50ï¼Œäººå·¥æ™ºèƒ½ä¸»é¢˜æŒ‡æ•°åº”ä¸º000885
    'ä¸­è¯ä¼ åª’æŒ‡æ•°': '399971',
    'ä¸­è¯è®¡ç®—æœºä¸»é¢˜æŒ‡æ•°': '399673',
    'åˆ›ä¸šæ¿50æŒ‡æ•°': '399673',
    'æ·±åœ³ç§‘æŠ€åˆ›æ–°ä¸»é¢˜æŒ‡æ•°': '399668',
    
    # --- è¡¥å……æ–°å¢è·³è¿‡çš„æŒ‡æ•° ---
    'ä¸­è¯1000æŒ‡æ•°': '000852',  # è¡¥å……
    'ä¸­è¯ç§‘åˆ›åˆ›ä¸š50æŒ‡æ•°': '931448',  # è¡¥å……
    'ä¸Šè¯ç§‘åˆ›æ¿50æˆä»½æŒ‡æ•°': '000688',  # åˆ«åï¼Œç¡®ä¿åŒ¹é…
    'ä¸­è¯å…¨æŒ‡ä¿¡æ¯æŠ€æœ¯æŒ‡æ•°': '000993',  # è¡¥å……
    'ä¸­è¯500ä¿¡æ¯æŠ€æœ¯æŒ‡æ•°': '000993',  # è¡¥å……
    'ä¸­è¯å…¨æŒ‡åŠå¯¼ä½“äº§å“ä¸è®¾å¤‡æŒ‡æ•°': 'H30184',  # è¡¥å…… (æŒ‡æ•°ä»£ç å¯èƒ½éœ€è¦éªŒè¯)
    'ä¸­è¯ç§‘æŠ€100æŒ‡æ•°': '931201',  # è¡¥å……
    'ä¸­è¯5Gé€šä¿¡ä¸»é¢˜æŒ‡æ•°': '931079',  # è¡¥å……
    'ä¸­è¯èŠ¯ç‰‡äº§ä¸šæŒ‡æ•°': '931071',  # è¡¥å……
    'ä¸­è¯äº‘è®¡ç®—ä¸å¤§æ•°æ®ä¸»é¢˜æŒ‡æ•°': '000992',  # è¡¥å……
    'å›½è¯åŠå¯¼ä½“èŠ¯ç‰‡æŒ‡æ•°': '980017',  # è¡¥å……
    'ä¸­è¯æµ·å¤–ä¸­å›½äº’è”ç½‘50äººæ°‘å¸æŒ‡æ•°': 'H30566',  # è¡¥å……
    'ä¸­è¯æ¶ˆè´¹ç”µå­ä¸»é¢˜æŒ‡æ•°': '931098' # è¡¥å……
}

# MACD å‚æ•°
SHORT_PERIOD = 12
LONG_PERIOD = 26
SIGNAL_PERIOD = 9

# æœ€å¤§é‡è¯•æ¬¡æ•°å’Œè¶…æ—¶è®¾ç½®
MAX_RETRIES = 5  # å¢åŠ åˆ°5æ¬¡ï¼Œæé«˜æˆåŠŸç‡
REQUEST_TIMEOUT = 30  # ç§’ï¼Œakshareå†…éƒ¨è¯·æ±‚è¶…æ—¶

# --- é…ç½®ç»“æŸ ---

def fetch_index_data(index_code, start_date):
    """
    ä½¿ç”¨ AkShare è·å–æŒ‡æ•°çš„æ—¥Kçº¿æ”¶ç›˜ä»·æ•°æ®ï¼Œå¹¶åŠ å…¥é‡è¯•æœºåˆ¶ã€‚
    """
    for attempt in range(MAX_RETRIES):
        try:
            if index_code == 'HSI':
                df = ak.index_global_hist(symbol="æ’ç”ŸæŒ‡æ•°", period="daily", start_date=start_date)
            else:
                # Aè‚¡æŒ‡æ•°
                df = ak.index_zh_a_hist(symbol=index_code, period="daily", start_date=start_date)
            
            # æˆåŠŸè·å–æ•°æ®ï¼Œè·³å‡ºå¾ªç¯
            if not df.empty:
                df.rename(columns={'æ—¥æœŸ': 'date', 'æ”¶ç›˜': 'close'}, inplace=True)
                return df[['date', 'close']].set_index('date')
            else:
                raise ValueError("è·å–çš„æ•°æ®ä¸ºç©º")
        
        # æ•è·ç½‘ç»œè¿æ¥ä¸­æ–­å’Œè¶…æ—¶ï¼Œä»¥åŠæ•°æ®ä¸ºç©ºçš„ ValueError
        except (ConnectionError, Timeout, http.client.RemoteDisconnected, ValueError) as e:
            # ConnectionError æ•è· requests çº§åˆ«çš„è¿æ¥é”™è¯¯
            # RemoteDisconnected æ•è·åº•å±‚ socket/http çº§åˆ«çš„è¿æ¥é”™è¯¯
            print(f" è­¦å‘Š: å°è¯• {attempt + 1}/{MAX_RETRIES} - æ— æ³•è·å– {index_code} æ•°æ®: {e.__class__.__name__} - {e}")
            if attempt < MAX_RETRIES - 1:
                # éšæœºå»¶è¿Ÿï¼Œé˜²æ­¢è¢«æ•°æ®æºå°ç¦
                sleep_time = random.uniform(5, 10)  # å¢åŠ å»¶è¿ŸèŒƒå›´
                print(f" ç­‰å¾… {sleep_time:.2f} ç§’åé‡è¯•...")
                time.sleep(sleep_time)
            else:
                print(f" é”™è¯¯: è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒè·å– {index_code} æ•°æ®ã€‚")
                return pd.DataFrame()
        
        except Exception as e:
            print(f" é”™è¯¯: å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼Œæ— æ³•è·å– {index_code} æ•°æ®: {e.__class__.__name__} - {e}")
            return pd.DataFrame()
    
    return pd.DataFrame()

def analyze_and_suggest(df_data, index_name, fund_name):
    """
    å¯¹å•ä¸€æŒ‡æ•°åº”ç”¨ MACD æŒ‡æ ‡ï¼Œå¹¶è¾“å‡ºä¹°å–ä¿¡å·ã€‚
    """
    if len(df_data) < LONG_PERIOD * 2:
        return f" [ {index_name} ] æ•°æ®ä¸è¶³ï¼ˆ{len(df_data)}æ¡ï¼‰ï¼Œè·³è¿‡æŠ€æœ¯åˆ†æã€‚"
    
    # è®¡ç®— MACD æŒ‡æ ‡
    df_nav = df_data.copy()
    # ç¡®ä¿è¾“å…¥æ˜¯ float ç±»å‹ï¼Œä»¥é¿å… talib è­¦å‘Š
    close_prices = df_nav['close'].values.astype(float) 
    
    df_nav['MACD'], df_nav['MACD_Signal'], df_nav['MACD_Hist'] = \
        talib.MACD(close_prices,
                   fastperiod=SHORT_PERIOD,
                   slowperiod=LONG_PERIOD,
                   signalperiod=SIGNAL_PERIOD)
    
    df_nav['Signal'] = np.where(df_nav['MACD'] > df_nav['MACD_Signal'], 1, 0)
    df_nav['Position'] = df_nav['Signal'].diff()
    
    # æå–æœ€è¿‘çš„äº¤æ˜“ä¿¡å·
    recent_signals = df_nav[df_nav['Position'].abs() == 1].tail(3)
    
    report_output = [f"\n--- ğŸ“ˆ {index_name} ({fund_name} çš„è·Ÿè¸ªæ ‡çš„) æœ€æ–°ä¿¡å· ---"]
    
    if recent_signals.empty:
        report_output.append(" æœªæ£€æµ‹åˆ°æœ‰æ•ˆä¿¡å·ã€‚")
    else:
        for index, row in recent_signals.iterrows():
            action = "ä¹°å…¥/åŠ ä»“" if row['Position'] == 1 else "å–å‡º/å‡ä»“"
            report_output.append(f" æ—¥æœŸ: {index}, ä¿¡å·: {action}, æŒ‡æ•°æ”¶ç›˜ä»·: {row['close']:.2f}")

    current_position = "å¤šå¤´ (å»ºè®®æŒæœ‰æˆ–åŠ ä»“)" if df_nav['Signal'].iloc[-1] == 1 else "ç©ºå¤´ (å»ºè®®è§‚æœ›æˆ–å‡ä»“)"
    report_output.append(f" å½“å‰çŠ¶æ€ ({df_nav.index[-1]}): {current_position}")
    
    return "\n".join(report_output)

def main_analysis():
    # 1. è¯»å– fund_basic_data_c_class.csv
    try:
        # ä½¿ç”¨ utf-8-sig åº”å¯¹å¯èƒ½å­˜åœ¨çš„ BOM
        df_funds = pd.read_csv('fund_basic_data_c_class.csv', encoding='utf_8_sig')
    except FileNotFoundError:
        return "é”™è¯¯ï¼šæœªæ‰¾åˆ° fund_basic_data_c_class.csv æ–‡ä»¶ã€‚è¯·ç¡®ä¿æ‚¨çš„æ•°æ®æŠ“å–å·¥ä½œæµå·²è¿è¡Œã€‚"
    except Exception as e:
        return f"è¯»å– CSV æ–‡ä»¶å‡ºé”™: {e}"
    
    # è®¾ç½®åˆ†ææ•°æ®çš„èµ·å§‹æ—¥æœŸä¸ºä¸€å¹´å‰
    start_date = (pd.Timestamp.today() - pd.DateOffset(years=1)).strftime('%Y%m%d')
    full_report = [f"ã€åŸºé‡‘è·Ÿè¸ªæ ‡çš„é‡åŒ–åˆ†ææŠ¥å‘Šã€‘\nç”Ÿæˆæ—¶é—´ï¼š{pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')} (UTC)\n--------------------------------------------------"]
    
    # 2. éå†æ¯åªåŸºé‡‘è¿›è¡Œåˆ†æ
    for index, row in df_funds.iterrows():
        fund_code = row['åŸºé‡‘ä»£ç ']
        fund_name = row['åŸºé‡‘ç®€ç§°']
        tracking_index_str = row['è·Ÿè¸ªæ ‡çš„']
        
        # 3. æ˜ç¡®è·³è¿‡ 'è¯¥åŸºé‡‘æ— è·Ÿè¸ªæ ‡çš„' æˆ–ä¸ºç©ºçš„è®°å½•
        if pd.isna(tracking_index_str) or tracking_index_str.strip() == 'è¯¥åŸºé‡‘æ— è·Ÿè¸ªæ ‡çš„' or not tracking_index_str.strip():
            continue
        
        header = f"\n==================================================\nğŸ”¬ æ­£åœ¨åˆ†ææŒ‡æ•°åŸºé‡‘: {fund_name} ({fund_code})\n è·Ÿè¸ªæ ‡çš„: {tracking_index_str}\n=================================================="
        full_report.append(header)
        
        # 4. å°è¯•ä»è·Ÿè¸ªæ ‡çš„å­—ç¬¦ä¸²ä¸­åŒ¹é…æŒ‡æ•°åç§° (ä¼˜åŒ–ï¼šå¿½ç•¥å¤§å°å†™ã€æ‹¬å·ã€ç‰¹æ®Šå­—ç¬¦)
        matched_index_name = None
        # ç§»é™¤æ‹¬å·ã€ç©ºæ ¼ã€è¿å­—ç¬¦å¹¶è½¬å°å†™
        cleaned_tracking_str = re.sub(r'[\(\ï¼ˆ\)\ï¼‰\s-]', '', tracking_index_str).strip().lower()  
        for name in INDEX_MAP.keys():
            cleaned_name = re.sub(r'[\(\ï¼ˆ\)\ï¼‰\s-]', '', name).strip().lower()
            if cleaned_name in cleaned_tracking_str or cleaned_tracking_str in cleaned_name:
                matched_index_name = name
                break
        
        if not matched_index_name:
            full_report.append(f" **è·³è¿‡:** è·Ÿè¸ªæ ‡çš„ '{tracking_index_str}' æœªåœ¨æ˜ å°„è¡¨ä¸­æˆ–æ— æ³•åŒ¹é…ã€‚")
            continue
        
        index_code = INDEX_MAP[matched_index_name]
        full_report.append(f"\n-> å¼€å§‹åˆ†æè·Ÿè¸ªæ ‡çš„: {matched_index_name} (ä»£ç : {index_code})")
        
        # 5. æŠ“å–æ•°æ®å¹¶åˆ†æ (åŒ…å«é‡è¯•é€»è¾‘)
        df_data = fetch_index_data(index_code, start_date)
        
        if not df_data.empty:
            analysis_result = analyze_and_suggest(df_data, matched_index_name, fund_name)
            full_report.append(analysis_result)
        else:
            full_report.append(f" **é”™è¯¯:** æ— æ³•è·å– {matched_index_name} çš„å†å²æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æŒ‡æ•°ä»£ç ã€‚")
        
        full_report.append("--------------------------------------------------")
    
    return "\n".join(full_report)

if __name__ == '__main__':
    # å¿…è¦çš„åº“æ£€æŸ¥
    try:
        import akshare
        import talib
        import pandas as pd
        import requests
        import http.client
    except ImportError as e:
        print(f"è‡´å‘½é”™è¯¯ï¼šè¯·ç¡®ä¿å·²å®‰è£… akshare, talib, pandas, requests åº“ã€‚ç¼ºå°‘: {e}")
        exit(1)
    
    report_content = main_analysis()
    
    # ç›´æ¥å°†æŠ¥å‘Šå†…å®¹è¾“å‡ºåˆ°æ ‡å‡†è¾“å‡ºï¼Œå·¥ä½œæµä¼šå°†å…¶é‡å®šå‘åˆ°æ–‡ä»¶
    print(report_content)
