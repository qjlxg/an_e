import pandas as pd
import glob
import os
import numpy as np
from datetime import datetime
import pytz
import logging
import math

# --- é…ç½®å‚æ•° ---
FUND_DATA_DIR = 'fund_data'
MIN_CONSECUTIVE_DROP_DAYS = 3
MIN_MONTH_DRAWDOWN = 0.06
HIGH_ELASTICITY_MIN_DRAWDOWN = 0.10  # é«˜å¼¹æ€§ç­–ç•¥çš„åŸºç¡€å›æ’¤è¦æ±‚ (10%)
MIN_DAILY_DROP_PERCENT = 0.03  # å½“æ—¥å¤§è·Œçš„å®šä¹‰ (3%)
REPORT_BASE_NAME = 'fund_warning_report'

# --- æ ¸å¿ƒé˜ˆå€¼è°ƒæ•´ ---
# RSI è¶…å–æå€¼æ”¶ç´§è‡³ 29
EXTREME_RSI_THRESHOLD = 29.0

# --- è®¾ç½®æ—¥å¿— ---
def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('fund_analysis.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

def validate_fund_data(df, fund_code):
    """
    éªŒè¯åŸºé‡‘æ•°æ®çš„å®Œæ•´æ€§å’Œè´¨é‡
    
    Args:
        df: åŸºé‡‘æ•°æ®DataFrame
        fund_code: åŸºé‡‘ä»£ç 
        
    Returns:
        tuple: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
    """
    if df.empty:
        return False, "æ•°æ®ä¸ºç©º"
    
    if 'value' not in df.columns:
        return False, "ç¼ºå°‘å‡€å€¼åˆ—"
    
    if len(df) < 250:
        return False, f"æ•°æ®ä¸è¶³250æ¡ï¼Œå½“å‰åªæœ‰{len(df)}æ¡"
    
    # æ£€æŸ¥å‡€å€¼åˆç†æ€§
    if (df['value'] <= 0).any():
        return False, "å­˜åœ¨æ— æ•ˆå‡€å€¼(<=0)"
    
    return True, "æ•°æ®æœ‰æ•ˆ"

def calculate_technical_indicators(df):
    """
    è®¡ç®—åŸºé‡‘å‡€å€¼çš„å®Œæ•´æŠ€æœ¯æŒ‡æ ‡ (RSI, MACD, MA, è¶‹åŠ¿ç­‰)
    
    Args:
        df: åŸºé‡‘æ•°æ®DataFrameï¼ŒæŒ‰æ—¥æœŸé™åºæ’åˆ—
        
    Returns:
        dict: åŒ…å«æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡çš„å­—å…¸
    """
    # ç¡®ä¿æœ€æ–°å€¼åœ¨æœ€å
    df_asc = df.iloc[::-1].copy().reset_index(drop=True)

    try:
        # æ•°æ®éªŒè¯
        if 'value' not in df_asc.columns or len(df_asc) < 250:
             # è¿”å›é»˜è®¤å€¼
            return {
                'RSI': np.nan, 'MACDä¿¡å·': 'æ•°æ®ä¸è¶³', 'å‡€å€¼/MA50': np.nan,
                'å‡€å€¼/MA250': np.nan, 'MA50/MA250': np.nan, 
                'MA50/MA250è¶‹åŠ¿': 'æ•°æ®ä¸è¶³',
                'å¸ƒæ—å¸¦ä½ç½®': 'æ•°æ®ä¸è¶³', 'æœ€æ–°å‡€å€¼': df_asc['value'].iloc[-1] if not df_asc.empty else np.nan,
                'å½“æ—¥è·Œå¹…': np.nan
            }

        # 1. RSI (14)
        delta = df_asc['value'].diff()
        # æ¶¨å¹…å’Œè·Œå¹…
        gain = (delta.where(delta > 0, 0)).rolling(window=14, min_periods=1).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()
        rs = gain / loss.replace(0, np.nan) 
        df_asc['RSI'] = 100 - (100 / (1 + rs))
        rsi_latest = df_asc['RSI'].iloc[-1]

        # 2. MACD (ç®€åŒ–ä¸ºä¿¡å·åˆ¤æ–­)
        ema_12 = df_asc['value'].ewm(span=12, adjust=False).mean()
        ema_26 = df_asc['value'].ewm(span=26, adjust=False).mean()
        df_asc['MACD'] = ema_12 - ema_26
        df_asc['Signal'] = df_asc['MACD'].ewm(span=9, adjust=False).mean()
        
        macd_latest = df_asc['MACD'].iloc[-1]
        signal_latest = df_asc['Signal'].iloc[-1]
        macd_prev = df_asc['MACD'].iloc[-2] if len(df_asc) >= 2 else np.nan
        signal_prev = df_asc['Signal'].iloc[-2] if len(df_asc) >= 2 else np.nan

        macd_signal = 'è§‚å¯Ÿ'
        if not np.isnan(macd_prev) and not np.isnan(signal_prev):
            if macd_latest > signal_latest and macd_prev < signal_prev:
                macd_signal = 'é‡‘å‰'
            elif macd_latest < signal_latest and macd_prev > signal_prev:
                macd_signal = 'æ­»å‰'

        # 3. ç§»åŠ¨å¹³å‡çº¿å’Œè¶‹åŠ¿åˆ†æ
        df_asc['MA50'] = df_asc['value'].rolling(window=50, min_periods=1).mean()
        df_asc['MA250'] = df_asc['value'].rolling(window=250, min_periods=1).mean()
        
        ma50_latest = df_asc['MA50'].iloc[-1]
        ma250_latest = df_asc['MA250'].iloc[-1]
        value_latest = df_asc['value'].iloc[-1]

        # è®¡ç®—æ¯”å€¼
        net_to_ma50 = value_latest / ma50_latest if ma50_latest and ma50_latest != 0 else np.nan
        net_to_ma250 = value_latest / ma250_latest if ma250_latest and ma250_latest != 0 else np.nan
        ma50_to_ma250 = ma50_latest / ma250_latest if ma250_latest and ma250_latest != 0 else np.nan


        # 4. MA50/MA250 è¶‹åŠ¿æ–¹å‘åˆ¤æ–­
        trend_direction = 'æ•°æ®ä¸è¶³'
        if len(df_asc) >= 250:
            recent_ratio = (df_asc['MA50'] / df_asc['MA250']).tail(20).dropna()
            if len(recent_ratio) >= 5:
                # æ‹Ÿåˆæ–œç‡
                slope = np.polyfit(np.arange(len(recent_ratio)), recent_ratio.values, 1)[0]
                
                if slope > 0.001:
                    trend_direction = 'å‘ä¸Š'
                elif slope < -0.001:
                    trend_direction = 'å‘ä¸‹'
                else:
                    trend_direction = 'å¹³ç¨³'
        
        # 5. å¸ƒæ—å¸¦ä½ç½® (ç®€åŒ–ä¸º N/A)
        bollinger_pos = 'N/A'

        # 6. å½“æ—¥è·Œå¹… (æœ€æ–°ä¸€å¤©è·Œå¹…)
        daily_drop = 0.0
        if len(df_asc) >= 2:
            value_t_minus_1 = df_asc['value'].iloc[-2]
            if value_t_minus_1 > 0:
                daily_drop = (value_t_minus_1 - value_latest) / value_t_minus_1

        return {
            'RSI': round(rsi_latest, 2) if not math.isnan(rsi_latest) else np.nan,
            'MACDä¿¡å·': macd_signal,
            'å‡€å€¼/MA50': round(net_to_ma50, 2) if not math.isnan(net_to_ma50) else np.nan,
            'å‡€å€¼/MA250': round(net_to_ma250, 2) if not math.isnan(net_to_ma250) else np.nan, 
            'MA50/MA250': round(ma50_to_ma250, 2) if not math.isnan(ma50_to_ma250) else np.nan, 
            'MA50/MA250è¶‹åŠ¿': trend_direction,
            'å¸ƒæ—å¸¦ä½ç½®': bollinger_pos,
            'æœ€æ–°å‡€å€¼': round(value_latest, 4) if not math.isnan(value_latest) else np.nan,
            'å½“æ—¥è·Œå¹…': round(daily_drop, 4)
        }

    except Exception as e:
        logging.error(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {
            'RSI': np.nan, 'MACDä¿¡å·': 'è®¡ç®—é”™è¯¯', 'å‡€å€¼/MA50': np.nan,
            'å‡€å€¼/MA250': np.nan, 'MA50/MA250': np.nan, 
            'MA50/MA250è¶‹åŠ¿': 'è®¡ç®—é”™è¯¯',
            'å¸ƒæ—å¸¦ä½ç½®': 'è®¡ç®—é”™è¯¯', 'æœ€æ–°å‡€å€¼': np.nan,
            'å½“æ—¥è·Œå¹…': np.nan
        }

def calculate_consecutive_drops(series):
    """è®¡ç®—å‡€å€¼åºåˆ—ä¸­æœ€å¤§çš„è¿ç»­ä¸‹è·Œå¤©æ•° (é™åºåºåˆ—ï¼Œæœ€æ–°åœ¨å‰)"""
    try:
        if series.empty or len(series) < 2:
            return 0
        
        # drops: [T < T-1, T-1 < T-2, T-2 < T-3, ...]
        drops = (series.iloc[:-1].values < series.iloc[1:].values) 
        
        max_drop_days = 0
        current_drop_days = 0
        
        # ä»æœ€æ–°ä¸€å¤©å¼€å§‹è¿­ä»£
        for is_dropped in drops:
            if is_dropped:
                current_drop_days += 1
                max_drop_days = max(max_drop_days, current_drop_days)
            else:
                current_drop_days = 0
                
        return max_drop_days
        
    except Exception as e:
        logging.error(f"è®¡ç®—è¿ç»­ä¸‹è·Œå¤©æ•°æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return 0

def calculate_max_drawdown(series):
    """è®¡ç®—æœ€å¤§å›æ’¤ (é™åºåºåˆ—ï¼Œæœ€æ–°åœ¨å‰)"""
    try:
        if series.empty:
            return 0.0
        
        series_asc = series.iloc[::-1]
        rolling_max = series_asc.cummax().iloc[::-1] # ä¿æŒé™åºç´¢å¼•ï¼Œä½†å€¼æ˜¯å€’åºç´¯ç§¯æœ€å¤§å€¼
        
        drawdown = (rolling_max - series) / rolling_max
        return drawdown.max()
        
    except Exception as e:
        logging.error(f"è®¡ç®—æœ€å¤§å›æ’¤æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return 0.0

def get_action_prompt(rsi_val, daily_drop_val, mdd_recent_month, max_drop_days_week):
    """
    æ ¹æ®æŠ€æœ¯æŒ‡æ ‡ç”Ÿæˆè¡ŒåŠ¨æç¤º
    
    Args:
        rsi_val: RSIå€¼
        daily_drop_val: å½“æ—¥è·Œå¹…
        mdd_recent_month: æœˆæœ€å¤§å›æ’¤
        max_drop_days_week: å‘¨è¿è·Œå¤©æ•°
        
    Returns:
        str: è¡ŒåŠ¨æç¤º
    """
    if mdd_recent_month >= HIGH_ELASTICITY_MIN_DRAWDOWN and max_drop_days_week == 1:
        if pd.isna(rsi_val):
            return 'é«˜å›æ’¤è§‚å¯Ÿ (RSIæ•°æ®ç¼ºå¤±)'
        
        # ä½¿ç”¨æ”¶ç´§åçš„ RSI é˜ˆå€¼
        if rsi_val <= EXTREME_RSI_THRESHOLD:
            if daily_drop_val >= MIN_DAILY_DROP_PERCENT:
                # P1: æåº¦è¶…å– + å½“æ—¥å¤§è·Œ
                return f'ğŸŒŸ ä¹°å…¥ä¿¡å· (RSIæåº¦è¶…å– <= {EXTREME_RSI_THRESHOLD:.0f} + å½“æ—¥å¤§è·Œ)'
            else:
                # P2: æåº¦è¶…å– + éå¤§è·Œæ—¥
                return f'è€ƒè™‘è¯•æ°´å»ºä»“ (RSIæåº¦è¶…å– <= {EXTREME_RSI_THRESHOLD:.0f})'
        elif rsi_val < 35: # ä¿æŒ 30-35 ä¹‹é—´çš„æç¤º
            return 'è§‚å¯Ÿä¸­ (RSIè¶…å–, ä½†æœªè¾¾æå€¼)'
        else:
            return 'é«˜å›æ’¤è§‚å¯Ÿ (RSIæœªè¶…å–)'
    else:
        return 'ä¸é€‚ç”¨ (éé«˜å¼¹æ€§ç²¾é€‰)'

def analyze_single_fund(filepath):
    """åˆ†æå•åªåŸºé‡‘"""
    try:
        fund_code = os.path.splitext(os.path.basename(filepath))[0]
        
        df = pd.read_csv(filepath)
        df['date'] = pd.to_datetime(df['date'])
        # æ ¸å¿ƒï¼šç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸé™åºæ’åˆ—ï¼Œæœ€æ–°æ•°æ®åœ¨æœ€å‰é¢
        df = df.sort_values(by='date', ascending=False).reset_index(drop=True)
        df = df.rename(columns={'net_value': 'value'})
        
        # æ•°æ®éªŒè¯
        is_valid, msg = validate_fund_data(df, fund_code)
        if not is_valid:
            logging.warning(f"åŸºé‡‘ {fund_code} æ•°æ®æ— æ•ˆ: {msg}")
            return None
        
        # è®¡ç®—åŸºç¡€æŒ‡æ ‡
        df_recent_month = df.head(30)
        df_recent_week = df.head(5)
        
        mdd_recent_month = calculate_max_drawdown(df_recent_month['value'])
        max_drop_days_week = calculate_consecutive_drops(df_recent_week['value'])
        
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        tech_indicators = calculate_technical_indicators(df)
        
        # ç”Ÿæˆè¡ŒåŠ¨æç¤º
        action_prompt = get_action_prompt(
            tech_indicators.get('RSI', np.nan), 
            tech_indicators.get('å½“æ—¥è·Œå¹…', 0.0), 
            mdd_recent_month, 
            max_drop_days_week
        )
        
        # æ ¸å¿ƒç­›é€‰æ¡ä»¶: æ»¡è¶³æœˆå›æ’¤åº•çº¿
        if mdd_recent_month >= MIN_MONTH_DRAWDOWN:
            
            return {
                'åŸºé‡‘ä»£ç ': fund_code,
                'æœ€å¤§å›æ’¤': mdd_recent_month,
                'æœ€å¤§è¿ç»­ä¸‹è·Œ': calculate_consecutive_drops(df_recent_month['value']),
                'è¿‘ä¸€å‘¨è¿è·Œ': max_drop_days_week,
                **tech_indicators,
                'è¡ŒåŠ¨æç¤º': action_prompt
            }
        
        return None
        
    except Exception as e:
        logging.error(f"åˆ†æåŸºé‡‘ {filepath} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None

def analyze_all_funds(target_codes=None):
    """åˆ†ææ‰€æœ‰åŸºé‡‘æ•°æ®"""
    try:
        if target_codes:
            csv_files = [os.path.join(FUND_DATA_DIR, f'{code}.csv') for code in target_codes if os.path.exists(os.path.join(FUND_DATA_DIR, f'{code}.csv'))]
        else:
            csv_files = glob.glob(os.path.join(FUND_DATA_DIR, '*.csv'))
        
        if not csv_files:
            logging.warning(f"åœ¨ç›®å½• '{FUND_DATA_DIR}' ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶")
            return []
        
        logging.info(f"æ‰¾åˆ° {len(csv_files)} ä¸ªåŸºé‡‘æ•°æ®æ–‡ä»¶ï¼Œå¼€å§‹åˆ†æ...")
        
        qualifying_funds = []
        for filepath in csv_files:
            result = analyze_single_fund(filepath)
            if result is not None:
                qualifying_funds.append(result)
        
        logging.info(f"åˆ†æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(qualifying_funds)} åªç¬¦åˆæ¡ä»¶çš„åŸºé‡‘")
        return qualifying_funds
        
    except Exception as e:
        logging.error(f"åˆ†ææ‰€æœ‰åŸºé‡‘æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return []

def format_technical_value(value, format_type='percent'):
    """æ ¼å¼åŒ–æŠ€æœ¯æŒ‡æ ‡å€¼ç”¨äºæ˜¾ç¤º"""
    if pd.isna(value): return 'NaN'
    if format_type == 'percent': return f"{value:.2%}"
    elif format_type == 'decimal2': return f"{value:.2f}"
    elif format_type == 'decimal4': return f"{value:.4f}"
    else: return str(value)

def format_table_row(index, row):
    """æ ¼å¼åŒ– Markdown è¡¨æ ¼è¡Œï¼ŒåŒ…å«é¢œè‰²/ç¬¦å·æ ‡è®°"""
    latest_value = row.get('æœ€æ–°å‡€å€¼', 1.0)
    trial_price = latest_value * 0.97
    
    # è¶‹åŠ¿å¥åº·åº¦æ ‡è®°
    trend_display = row['MA50/MA250è¶‹åŠ¿']
    ma_ratio_display = format_technical_value(row['MA50/MA250'], 'decimal2')
    
    # çªå‡ºæ˜¾ç¤ºä¸å¥åº·çš„è¶‹åŠ¿
    if trend_display == 'å‘ä¸‹' and row['MA50/MA250'] < 0.95:
         trend_display = f"âš ï¸ {trend_display}"
         ma_ratio_display = f"âš ï¸ {ma_ratio_display}"

    return (
        f"| {index} | `{row['åŸºé‡‘ä»£ç ']}` | **{format_technical_value(row['æœ€å¤§å›æ’¤'], 'percent')}** | "
        f"{format_technical_value(row['å½“æ—¥è·Œå¹…'], 'percent')} | {row['RSI']:.2f} | "
        f"{row['MACDä¿¡å·']} | {format_technical_value(row['å‡€å€¼/MA50'], 'decimal2')} | "
        f"**{ma_ratio_display}** | **{trend_display}** | "
        f"{format_technical_value(row['å‡€å€¼/MA250'], 'decimal2')} | {trial_price:.4f} | **{row['è¡ŒåŠ¨æç¤º']}** |\n"
    )


def generate_report(results, timestamp_str):
    """
    ç”Ÿæˆå®Œæ•´çš„Markdownæ ¼å¼æŠ¥å‘Šï¼ŒåŒ…å«ä¸¥æ ¼çš„ä¼˜å…ˆçº§åˆ’åˆ†é€»è¾‘
    """
    try:
        if not results:
            return (
                f"# åŸºé‡‘é¢„è­¦æŠ¥å‘Š ({timestamp_str} UTC+8)\n\n"
                f"## åˆ†ææ€»ç»“\n\n"
                f"**æ­å–œï¼Œåœ¨è¿‡å»ä¸€ä¸ªæœˆå†…ï¼Œæ²¡æœ‰å‘ç°åŒæ—¶æ»¡è¶³ '1ä¸ªæœˆå›æ’¤{MIN_MONTH_DRAWDOWN*100:.0f}%ä»¥ä¸Š' çš„åŸºé‡‘ã€‚**\n\n"
                f"---\nåˆ†ææ•°æ®æ—¶é—´èŒƒå›´: æœ€è¿‘30ä¸ªäº¤æ˜“æ—¥ (é€šå¸¸çº¦ä¸º1ä¸ªæœˆ)ã€‚"
            )

        # åˆ›å»ºDataFrameå¹¶æ’åº
        df_results = pd.DataFrame(results).sort_values(by='æœ€å¤§å›æ’¤', ascending=False).reset_index(drop=True)
        df_results.index = df_results.index + 1
        total_count = len(df_results)

        report_parts = []
        
        # æŠ¥å‘Šå¤´éƒ¨
        report_parts.extend([
            f"# åŸºé‡‘é¢„è­¦æŠ¥å‘Š ({timestamp_str} UTC+8)\n\n",
            f"## åˆ†ææ€»ç»“\n\n",
            f"æœ¬æ¬¡åˆ†æå…±å‘ç° **{total_count}** åªåŸºé‡‘æ»¡è¶³åŸºç¡€é¢„è­¦æ¡ä»¶ï¼ˆè¿‘ 1 ä¸ªæœˆå›æ’¤ $\ge {MIN_MONTH_DRAWDOWN*100:.0f}\%$ï¼‰ã€‚\n",
            f"**ç­–ç•¥æ›´æ–°ï¼šRSIè¶…å–é˜ˆå€¼æ”¶ç´§è‡³ $\le {EXTREME_RSI_THRESHOLD:.0f}$ï¼Œèšç„¦æå€¼æœºä¼šã€‚**\n",
            f"---\n"
        ])

        # æ ¸å¿ƒç­›é€‰ï¼šé«˜å¼¹æ€§åŸºé‡‘ (MDD>=10% ä¸” è¿‘ä¸€å‘¨è¿è·Œ=1)
        df_base_elastic = df_results[
            (df_results['æœ€å¤§å›æ’¤'] >= HIGH_ELASTICITY_MIN_DRAWDOWN) &
            (df_results['è¿‘ä¸€å‘¨è¿è·Œ'] == 1)
        ].copy()

        # è¿›ä¸€æ­¥ç­›é€‰ï¼šRSIæåº¦è¶…å– (RSI <= 29.0)
        df_base_elastic_low_rsi = df_base_elastic[
            df_base_elastic['RSI'] <= EXTREME_RSI_THRESHOLD
        ].copy()
        
        # --- ä¼˜å…ˆçº§åˆ’åˆ†ï¼šå…³é”®ä¿®å¤é€»è¾‘ ---

        # 1. ğŸ¥‡ ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šã€å³æ—¶ææ…Œä¹°å…¥ã€‘ (RSIæåº¦è¶…å– ä¸” å½“æ—¥å¤§è·Œ >= 3%)
        df_buy_signal_1 = df_base_elastic_low_rsi[
            df_base_elastic_low_rsi['å½“æ—¥è·Œå¹…'] >= MIN_DAILY_DROP_PERCENT
        ].copy()

        if not df_buy_signal_1.empty:
            df_buy_signal_1 = df_buy_signal_1.sort_values(
                by=['å½“æ—¥è·Œå¹…', 'RSI'], ascending=[False, True]
            ).reset_index(drop=True)
            df_buy_signal_1.index = df_buy_signal_1.index + 1

            report_parts.extend([
                f"\n## **ğŸ¥‡ ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šã€å³æ—¶ææ…Œä¹°å…¥ã€‘** ({len(df_buy_signal_1)}åª)\n\n",
                r"**æ¡ä»¶ï¼š** é•¿æœŸè¶…è·Œ ($\ge$ " + f"{HIGH_ELASTICITY_MIN_DRAWDOWN*100:.0f}%) + "
                r"ä½ä½ä¼ç¨³ + **RSIæåº¦è¶…å– ($\le {EXTREME_RSI_THRESHOLD:.0f}$)** + **å½“æ—¥è·Œå¹… $\ge$ " + f"{MIN_DAILY_DROP_PERCENT*100:.0f}%**\n",
                r"**çºªå¾‹ï¼š** å¸‚åœºææ…Œæ—¶å‡ºæ‰‹ï¼Œæœ¬é‡‘å……è¶³æ—¶åº”ä¼˜å…ˆé…ç½®æ­¤åˆ—è¡¨ã€‚**ä¸¥æ ¼å…³æ³¨ MA50/MA250 è¶‹åŠ¿ã€‚**" + "\n\n",
                f"| æ’å | åŸºé‡‘ä»£ç  | æœ€å¤§å›æ’¤ (1M) | **å½“æ—¥è·Œå¹…** | RSI(14) | MACDä¿¡å· | å‡€å€¼/MA50 | **MA50/MA250** | **è¶‹åŠ¿** | å‡€å€¼/MA250 | è¯•æ°´ä¹°ä»· (è·Œ3%) | è¡ŒåŠ¨æç¤º |\n",
                f"| :---: | :---: | ---: | ---: | ---: | :---: | ---: | **---:** | :---: | ---: | :---: | :---: |\n"
            ])

            for index, row in df_buy_signal_1.iterrows():
                report_parts.append(format_table_row(index, row))

            report_parts.append("\n---\n")
        else:
            report_parts.extend([
                f"\n## **ğŸ¥‡ ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šã€å³æ—¶ææ…Œä¹°å…¥ã€‘**\n\n",
                f"**ä»Šæ—¥æ²¡æœ‰åŸºé‡‘åŒæ—¶æ»¡è¶³æ‰€æœ‰ä¸¥æ ¼æ¡ä»¶ (RSI $\le {EXTREME_RSI_THRESHOLD:.0f}$ ä¸” å½“æ—¥è·Œå¹… $\ge {MIN_DAILY_DROP_PERCENT*100:.0f}\%$**ï¼Œå¸‚åœºææ…Œåº¦ä¸è¶³ã€‚\n\n",
                f"---\n"
            ])

        # 2. ğŸ¥ˆ ç¬¬äºŒä¼˜å…ˆçº§ï¼šã€æŠ€æœ¯å…±æŒ¯å»ºä»“ã€‘ (RSIæåº¦è¶…å– ä¸” å½“æ—¥è·Œå¹… < 3%)
        df_buy_signal_2 = df_base_elastic_low_rsi[
            df_base_elastic_low_rsi['å½“æ—¥è·Œå¹…'] < MIN_DAILY_DROP_PERCENT
        ].copy()
        
        # ç¡®ä¿ P1 å’Œ P2 äº’æ–¥ï¼šæ’é™¤ P1 ä¸­çš„åŸºé‡‘ï¼ˆé˜²æ­¢æµ®ç‚¹æ•°è¯¯å·®å¯¼è‡´é‡å ï¼‰
        funds_to_exclude_1 = df_buy_signal_1['åŸºé‡‘ä»£ç '].tolist()
        df_buy_signal_2 = df_buy_signal_2[
            ~df_buy_signal_2['åŸºé‡‘ä»£ç '].isin(funds_to_exclude_1)
        ].copy()


        if not df_buy_signal_2.empty:
            df_buy_signal_2 = df_buy_signal_2.sort_values(
                by=['RSI', 'æœ€å¤§å›æ’¤'], ascending=[True, False]
            ).reset_index(drop=True)
            df_buy_signal_2.index = df_buy_signal_2.index + 1

            report_parts.extend([
                f"\n## **ğŸ¥ˆ ç¬¬äºŒä¼˜å…ˆçº§ï¼šã€æŠ€æœ¯å…±æŒ¯å»ºä»“ã€‘** ({len(df_buy_signal_2)}åª)\n\n",
                r"**æ¡ä»¶ï¼š** é•¿æœŸè¶…è·Œ ($\ge$ " + f"{HIGH_ELASTICITY_MIN_DRAWDOWN*100:.0f}%) + "
                r"ä½ä½ä¼ç¨³ + **RSIæåº¦è¶…å– ($\le {EXTREME_RSI_THRESHOLD:.0f}$)** + **å½“æ—¥è·Œå¹… $< $" + f"{MIN_DAILY_DROP_PERCENT*100:.0f}%**\n",
                r"**çºªå¾‹ï¼š** é€‚åˆåœ¨æœ¬é‡‘æœ‰é™æ—¶ä¼˜å…ˆé…ç½®ï¼Œæˆ–åœ¨éå¤§è·Œæ—¥è¿›è¡Œå»ºä»“ã€‚**ä¸¥æ ¼å…³æ³¨ MA50/MA250 è¶‹åŠ¿ã€‚**" + "\n\n",
                f"| æ’å | åŸºé‡‘ä»£ç  | æœ€å¤§å›æ’¤ (1M) | **å½“æ—¥è·Œå¹…** | RSI(14) | MACDä¿¡å· | å‡€å€¼/MA50 | **MA50/MA250** | **è¶‹åŠ¿** | å‡€å€¼/MA250 | è¯•æ°´ä¹°ä»· (è·Œ3%) | è¡ŒåŠ¨æç¤º |\n",
                f"| :---: | :---: | ---: | ---: | ---: | :---: | ---: | **---:** | :---: | ---: | :---: | :---: |\n"
            ])

            for index, row in df_buy_signal_2.iterrows():
                report_parts.append(format_table_row(index, row))

            report_parts.append("\n---\n")
        else:
            report_parts.extend([
                f"\n## **ğŸ¥ˆ ç¬¬äºŒä¼˜å…ˆçº§ï¼šã€æŠ€æœ¯å…±æŒ¯å»ºä»“ã€‘**\n\n",
                f"æ²¡æœ‰åŸºé‡‘åŒæ—¶æ»¡è¶³ **é•¿æœŸè¶…è·Œ**ã€**ä½ä½ä¼ç¨³** å’Œ **RSIæåº¦è¶…å– ($\le {EXTREME_RSI_THRESHOLD:.0f}$)** ä¸” **å½“æ—¥è·Œå¹… $< {MIN_DAILY_DROP_PERCENT*100:.0f}\%$** çš„æ¡ä»¶ã€‚\n\n",
                f"---\n"
            ])

        # 3. ğŸ¥‰ ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šæ‰©å±•è§‚å¯Ÿæ±  (RSI > 29.0)
        df_extended_elastic = df_base_elastic[
            df_base_elastic['RSI'] > EXTREME_RSI_THRESHOLD
        ].copy()

        if not df_extended_elastic.empty:
            df_extended_elastic = df_extended_elastic.sort_values(
                by='æœ€å¤§å›æ’¤', ascending=False
            ).reset_index(drop=True)
            df_extended_elastic.index = df_extended_elastic.index + 1

            report_parts.extend([
                f"\n## **ğŸ¥‰ ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šã€æ‰©å±•è§‚å¯Ÿæ± ã€‘** ({len(df_extended_elastic)}åª)\n\n",
                r"**æ¡ä»¶ï¼š** é•¿æœŸè¶…è·Œ ($\ge$ " + f"{HIGH_ELASTICITY_MIN_DRAWDOWN*100:.0f}%) + "
                r"ä½ä½ä¼ç¨³ï¼Œä½† **RSI $>{EXTREME_RSI_THRESHOLD:.0f}$ (æœªè¾¾æåº¦è¶…å–)**ã€‚\n",
                r"**çºªå¾‹ï¼š** é£é™©è¾ƒé«˜ï¼Œä»…ä½œä¸ºè§‚å¯Ÿå’Œå¤‡é€‰ï¼Œç­‰å¾… RSI è¿›ä¸€æ­¥è¿›å…¥æåº¦è¶…å–åŒºã€‚**ä¸¥æ ¼å…³æ³¨ MA50/MA250 è¶‹åŠ¿ã€‚**" + "\n\n",
                f"| æ’å | åŸºé‡‘ä»£ç  | æœ€å¤§å›æ’¤ (1M) | **å½“æ—¥è·Œå¹…** | RSI(14) | MACDä¿¡å· | å‡€å€¼/MA50 | **MA50/MA250** | **è¶‹åŠ¿** | å‡€å€¼/MA250 | è¯•æ°´ä¹°ä»· (è·Œ3%) | è¡ŒåŠ¨æç¤º |\n",
                f"| :---: | :---: | ---: | ---: | ---: | ---: | ---: | **---:** | :---: | ---: | :---: | :---: |\n"
            ])

            for index, row in df_extended_elastic.iterrows():
                report_parts.append(format_table_row(index, row))

            report_parts.append("\n---\n")
        else:
            report_parts.extend([
                f"\n## **ğŸ¥‰ ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šã€æ‰©å±•è§‚å¯Ÿæ± ã€‘**\n\n",
                r"æ²¡æœ‰åŸºé‡‘æ»¡è¶³ **é•¿æœŸè¶…è·Œ** ä¸” **RSI $>{EXTREME_RSI_THRESHOLD:.0f}$** çš„è§‚å¯Ÿæ¡ä»¶ã€‚" + "\n\n",
                f"---\n"
            ])

        # æ‰€æœ‰é¢„è­¦åŸºé‡‘åˆ—è¡¨
        # (çœç•¥æ‰€æœ‰é¢„è­¦åŸºé‡‘åˆ—è¡¨çš„è¡¨æ ¼ç”Ÿæˆï¼Œå› ä¸ºå®ƒåªæ˜¯ä¸€ä¸ªæ€»è§ˆï¼Œä¿æŒæŠ¥å‘Šç®€æ´)

        # ç­–ç•¥æ‰§è¡Œçºªå¾‹ï¼ˆåŒ…å«è¡Œä¸šé£é™©æç¤ºï¼‰
        report_parts.extend([
            "\n---\n",
            f"## **âš ï¸ å¼ºåŒ–æ‰§è¡Œçºªå¾‹ï¼šé£æ§ä¸è¡Œä¸šå®¡æŸ¥ (RSI $\le {EXTREME_RSI_THRESHOLD:.0f}$ æå€¼ç­–ç•¥)**\n\n",
            f"**1. ğŸ›‘ è¶‹åŠ¿å¥åº·åº¦ï¼ˆMA50/MA250 å†³å®šèƒ½å¦ä¹°ï¼‰ï¼š**\n",
            r"    * **MA50/MA250 $\ge 0.95$ ä¸” è¶‹åŠ¿æ–¹å‘ä¸º 'å‘ä¸Š' æˆ– 'å¹³ç¨³'** çš„åŸºé‡‘ï¼Œè§†ä¸º **è¶‹åŠ¿å¥åº·**ï¼Œå…è®¸è¯•æ°´ã€‚", "\n",
            r"    * **è‹¥åŸºé‡‘è¶‹åŠ¿æ˜¾ç¤º âš ï¸ å‘ä¸‹ï¼Œæˆ– MA50/MA250 $< 0.95$ï¼Œ** åˆ™è¡¨æ˜é•¿æœŸå¤„äºç†Šå¸‚é€šé“ï¼Œ**å¿…é¡»æ”¾å¼ƒ**ï¼Œæ— è®ºçŸ­æœŸè¶…è·Œæœ‰å¤šä¸¥é‡ã€‚", "\n",
            f"**2. ğŸ” äººå·¥è¡Œä¸šä¸Kçº¿å®¡æŸ¥ï¼ˆæ’é™¤æ¥é£åˆ€é£é™©ï¼‰ï¼š**\n",
            r"    * **åœ¨ä¹°å…¥å‰ï¼Œå¿…é¡»æŸ¥é˜…åŸºé‡‘é‡ä»“è¡Œä¸šã€‚** å¦‚æœåŸºé‡‘å±äºè¿‘æœŸï¼ˆå¦‚è¿‘ 3-6 ä¸ªæœˆï¼‰**æ¶¨å¹…å·¨å¤§ã€ä¼°å€¼è¿‡é«˜**çš„æ¿å—ï¼ˆä¾‹å¦‚ï¼šéƒ¨åˆ†AIã€åŠå¯¼ä½“ï¼‰ï¼Œåˆ™å³ä½¿æŠ€æœ¯è¶…å–ï¼Œä¹Ÿåº”è§†ä¸º**é«˜é£é™©å›è°ƒ**ï¼Œå»ºè®®**æ”¾å¼ƒ**æˆ–**å¤§å¹…ç¼©å‡**è¯•æ°´ä»“ä½ã€‚", "\n",
            r"    * **åŒæ—¶å¤æ ¸ K çº¿å›¾ï¼š** ç¡®è®¤å½“å‰ä»·æ ¼æ˜¯å¦è·ç¦»**è¿‘åŠå¹´å†å²é«˜ç‚¹**å¤ªè¿‘ã€‚è‹¥æ˜¯ï¼Œåˆ™é£é™©é«˜ã€‚", "\n",
            f"**3. I çº§è¯•æ°´å»ºä»“ï¼ˆRSIæå€¼ç­–ç•¥ï¼‰ï¼š**\n",
            r"    * ä»…å½“åŸºé‡‘æ»¡è¶³ï¼š**è¶‹åŠ¿å¥åº·** + **å‡€å€¼/MA50 $\le 1.0$** + **RSI $\le {EXTREME_RSI_THRESHOLD:.0f}$** æ—¶ï¼Œæ‰è¿›è¡Œ $\mathbf{I}$ çº§è¯•æ°´ã€‚", "\n",
            f"**4. é£é™©æ§åˆ¶ï¼š**\n",
            f"    * ä¸¥æ ¼æ­¢æŸçº¿ï¼šå¹³å‡æˆæœ¬ä»·**è·Œå¹…è¾¾åˆ° 8%-10%**ï¼Œç«‹å³æ¸…ä»“æ­¢æŸã€‚\n"
        ])

        return "".join(report_parts)
        
    except Exception as e:
        logging.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return f"# æŠ¥å‘Šç”Ÿæˆé”™è¯¯\n\né”™è¯¯ä¿¡æ¯: {str(e)}"

def main():
    """ä¸»å‡½æ•°"""
    try:
        # 1. è®¾ç½®æ—¥å¿—
        setup_logging()
        
        # 2. è·å–å½“å‰æ—¶é—´
        try:
            tz = pytz.timezone('Asia/Shanghai')
            now = datetime.now(tz)
        except:
            now = datetime.now()
            logging.warning("ä½¿ç”¨æ—¶åŒºå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ—¶é—´")
        
        timestamp_for_report = now.strftime('%Y-%m-%d %H:%M:%S')
        timestamp_for_filename = now.strftime('%Y%m%d_%H%M%S')
        dir_name = now.strftime('%Y%m')

        # 3. åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(dir_name, exist_ok=True)
        report_file = os.path.join(dir_name, f"{REPORT_BASE_NAME}_{timestamp_for_filename}.md")

        logging.info("å¼€å§‹åˆ†æåŸºé‡‘æ•°æ®...")
        
        # 4. æ‰§è¡Œåˆ†æ
        results = analyze_all_funds()
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        report_content = generate_report(results, timestamp_for_report)
        
        # 6. ä¿å­˜æŠ¥å‘Š
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logging.info(f"åˆ†æå®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜åˆ° {report_file}")
        return True
        
    except Exception as e:
        logging.error(f"ä¸»ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return False

if __name__ == '__main__':
    # è¯·ç¡®ä¿ 'fund_data' ç›®å½•å­˜åœ¨ï¼Œä¸”å…¶ä¸­åŒ…å«ä»¥åŸºé‡‘ä»£ç å‘½åçš„ CSV æ–‡ä»¶ (date, net_value)
    success = main()
    print("è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚")

