import pandas as pd
import glob
import os
import numpy as np
from datetime import datetime
import pytz
import logging
import math

# --- é…ç½®å‚æ•° ---
FUND_DATA_DIR = 'fund_data'
MIN_CONSECUTIVE_DROP_DAYS = 3
MIN_MONTH_DRAWDOWN = 0.06
HIGH_ELASTICITY_MIN_DRAWDOWN = 0.10  # é«˜å¼¹æ€§ç­–ç•¥çš„åŸºç¡€å›æ’¤è¦æ±‚ (10%)
MIN_DAILY_DROP_PERCENT = 0.03  # å½“æ—¥å¤§è·Œçš„å®šä¹‰ (3%)
REPORT_BASE_NAME = 'fund_warning_report'

# --- æ ¸å¿ƒé˜ˆå€¼è°ƒæ•´ ---
EXTREME_RSI_THRESHOLD_P1 = 29.0 
STRONG_RSI_THRESHOLD_P2 = 35.0

# --- è®¾ç½®æ—¥å¿— ---
def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('fund_analysis.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

def validate_fund_data(df, fund_code):
    """éªŒè¯åŸºé‡‘æ•°æ®çš„å®Œæ•´æ€§å’Œè´¨é‡"""
    if df.empty: return False, "æ•°æ®ä¸ºç©º"
    if 'value' not in df.columns: return False, "ç¼ºå°‘å‡€å€¼åˆ—"
    if len(df) < 250: return False, f"æ•°æ®ä¸è¶³250æ¡ï¼Œå½“å‰åªæœ‰{len(df)}æ¡"
    if (df['value'] <= 0).any(): return False, "å­˜åœ¨æ— æ•ˆå‡€å€¼(<=0)"
    return True, "æ•°æ®æœ‰æ•ˆ"

def calculate_bollinger_bands(series, window=20):
    """è®¡ç®—å¸ƒæ—å¸¦ä½ç½®"""
    if len(series) < window:
        return "æ•°æ®ä¸è¶³"
    
    df_temp = pd.DataFrame({'value': series.values})
    df_temp['MA20'] = df_temp['value'].rolling(window=window).mean()
    df_temp['STD20'] = df_temp['value'].rolling(window=window).std()
    
    # ç¡®ä¿æ²¡æœ‰é™¤ä»¥é›¶
    if df_temp['STD20'].iloc[-1] == 0:
        return "æ³¢åŠ¨æå°"
        
    df_temp['Upper Band'] = df_temp['MA20'] + (df_temp['STD20'] * 2)
    df_temp['Lower Band'] = df_temp['MA20'] - (df_temp['STD20'] * 2)
    
    latest_value = df_temp['value'].iloc[-1]
    latest_lower = df_temp['Lower Band'].iloc[-1]
    latest_upper = df_temp['Upper Band'].iloc[-1]
    
    if pd.isna(latest_lower) or pd.isna(latest_upper):
        return "æ•°æ®ä¸è¶³"
        
    if latest_value <= latest_lower:
        return "**ä¸‹è½¨ä¸‹æ–¹**" 
    elif latest_value >= latest_upper:
        return "**ä¸Šè½¨ä¸Šæ–¹**" 
    else:
        # å½’ä¸€åŒ–ä½ç½®
        range_band = latest_upper - latest_lower
        if range_band == 0:
             return "è½¨é“ä¸­é—´" 
             
        position = (latest_value - latest_lower) / range_band
        if position < 0.2:
            return "ä¸‹è½¨é™„è¿‘"
        elif position > 0.8:
            return "ä¸Šè½¨é™„è¿‘"
        else:
            return "è½¨é“ä¸­é—´"

def calculate_technical_indicators(df):
    """è®¡ç®—åŸºé‡‘å‡€å€¼çš„å®Œæ•´æŠ€æœ¯æŒ‡æ ‡ (RSI, MACD, MA, è¶‹åŠ¿ç­‰)"""
    # ç¡®ä¿æœ€æ–°å€¼åœ¨æœ€å
    df_asc = df.iloc[::-1].copy().reset_index(drop=True)

    try:
        if 'value' not in df_asc.columns or len(df_asc) < 250:
            return {
                'RSI': np.nan, 'MACDä¿¡å·': 'æ•°æ®ä¸è¶³', 'å‡€å€¼/MA50': np.nan,
                'å‡€å€¼/MA250': np.nan, 'MA50/MA250': np.nan, 
                'MA50/MA250è¶‹åŠ¿': 'æ•°æ®ä¸è¶³',
                'å¸ƒæ—å¸¦ä½ç½®': 'æ•°æ®ä¸è¶³', 'æœ€æ–°å‡€å€¼': df_asc['value'].iloc[-1] if not df_asc.empty else np.nan,
                'å½“æ—¥è·Œå¹…': np.nan
            }

        # 1. RSI (14)
        delta = df_asc['value'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14, min_periods=1).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()
        rs = gain / loss.replace(0, np.nan) 
        df_asc['RSI'] = 100 - (100 / (1 + rs))
        rsi_latest = df_asc['RSI'].iloc[-1]

        # 2. MACD (ç®€åŒ–ä¸ºä¿¡å·åˆ¤æ–­)
        ema_12 = df_asc['value'].ewm(span=12, adjust=False).mean()
        ema_26 = df_asc['value'].ewm(span=26, adjust=False).mean()
        df_asc['MACD'] = ema_12 - ema_26
        df_asc['Signal'] = df_asc['MACD'].ewm(span=9, adjust=False).mean()
        macd_latest = df_asc['MACD'].iloc[-1]
        signal_latest = df_asc['Signal'].iloc[-1]
        macd_prev = df_asc['MACD'].iloc[-2] if len(df_asc) >= 2 else np.nan
        signal_prev = df_asc['Signal'].iloc[-2] if len(df_asc) >= 2 else np.nan
        macd_signal = 'è§‚å¯Ÿ'
        if not np.isnan(macd_prev) and not np.isnan(signal_prev):
            if macd_latest > signal_latest and macd_prev < signal_prev: macd_signal = 'é‡‘å‰'
            elif macd_latest < signal_latest and macd_prev > signal_prev: macd_signal = 'æ­»å‰'

        # 3. ç§»åŠ¨å¹³å‡çº¿å’Œè¶‹åŠ¿åˆ†æ
        df_asc['MA50'] = df_asc['value'].rolling(window=50, min_periods=1).mean()
        df_asc['MA250'] = df_asc['value'].rolling(window=250, min_periods=1).mean()
        ma50_latest = df_asc['MA50'].iloc[-1]
        ma250_latest = df_asc['MA250'].iloc[-1]
        value_latest = df_asc['value'].iloc[-1]
        net_to_ma50 = value_latest / ma50_latest if ma50_latest and ma50_latest != 0 else np.nan
        net_to_ma250 = value_latest / ma250_latest if ma250_latest and ma250_latest != 0 else np.nan
        ma50_to_ma250 = ma50_latest / ma250_latest if ma250_latest and ma250_latest != 0 else np.nan

        # 4. MA50/MA250 è¶‹åŠ¿æ–¹å‘åˆ¤æ–­
        trend_direction = 'æ•°æ®ä¸è¶³'
        if len(df_asc) >= 250:
            recent_ratio = (df_asc['MA50'] / df_asc['MA250']).tail(20).dropna()
            if len(recent_ratio) >= 5:
                slope = np.polyfit(np.arange(len(recent_ratio)), recent_ratio.values, 1)[0]
                if slope > 0.001: trend_direction = 'å‘ä¸Š'
                elif slope < -0.001: trend_direction = 'å‘ä¸‹'
                else: trend_direction = 'å¹³ç¨³'
        
        # 5. å½“æ—¥è·Œå¹… (æœ€æ–°ä¸€å¤©è·Œå¹…)
        daily_drop = 0.0
        if len(df_asc) >= 2:
            value_t_minus_1 = df_asc['value'].iloc[-2]
            if value_t_minus_1 > 0:
                daily_drop = (value_t_minus_1 - value_latest) / value_t_minus_1
                
        # 6. å¸ƒæ—å¸¦ä½ç½®
        bollinger_position = calculate_bollinger_bands(df_asc['value'])

        return {
            'RSI': round(rsi_latest, 2) if not math.isnan(rsi_latest) else np.nan,
            'MACDä¿¡å·': macd_signal,
            'å‡€å€¼/MA50': round(net_to_ma50, 2) if not math.isnan(net_to_ma50) else np.nan,
            'å‡€å€¼/MA250': round(net_to_ma250, 2) if not math.isnan(net_to_ma250) else np.nan, 
            'MA50/MA250': round(ma50_to_ma250, 2) if not math.isnan(ma50_to_ma250) else np.nan, 
            'MA50/MA250è¶‹åŠ¿': trend_direction,
            'å¸ƒæ—å¸¦ä½ç½®': bollinger_position, 
            'æœ€æ–°å‡€å€¼': round(value_latest, 4) if not math.isnan(value_latest) else np.nan,
            'å½“æ—¥è·Œå¹…': round(daily_drop, 4) 
        }

    except Exception as e:
        logging.error(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {
            'RSI': np.nan, 'MACDä¿¡å·': 'è®¡ç®—é”™è¯¯', 'å‡€å€¼/MA50': np.nan,
            'å‡€å€¼/MA250': np.nan, 'MA50/MA250': np.nan, 
            'MA50/MA250è¶‹åŠ¿': 'è®¡ç®—é”™è¯¯',
            'å¸ƒæ—å¸¦ä½ç½®': 'è®¡ç®—é”™è¯¯',
            'æœ€æ–°å‡€å€¼': np.nan,
            'å½“æ—¥è·Œå¹…': np.nan
        }

def calculate_consecutive_drops(series):
    """è®¡ç®—å‡€å€¼åºåˆ—ä¸­æœ€å¤§çš„è¿ç»­ä¸‹è·Œå¤©æ•°"""
    try:
        if series.empty or len(series) < 2: return 0
        drops = (series.iloc[:-1].values < series.iloc[1:].values) 
        max_drop_days = 0
        current_drop_days = 0
        for is_dropped in drops:
            if is_dropped:
                current_drop_days += 1
                max_drop_days = max(max_drop_days, current_drop_days)
            else:
                current_drop_days = 0
        return max_drop_days
    except Exception as e:
        logging.error(f"è®¡ç®—è¿ç»­ä¸‹è·Œå¤©æ•°æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return 0

def calculate_max_drawdown(series):
    """è®¡ç®—æœ€å¤§å›æ’¤"""
    try:
        if series.empty: return 0.0
        series_asc = series.iloc[::-1]
        rolling_max = series_asc.cummax().iloc[::-1]
        drawdown = (rolling_max - series) / rolling_max
        return drawdown.max()
    except Exception as e:
        logging.error(f"è®¡ç®—æœ€å¤§å›æ’¤æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return 0.0

def get_action_prompt(rsi_val, daily_drop_val, mdd_recent_month, max_drop_days_week):
    """æ ¹æ®æŠ€æœ¯æŒ‡æ ‡ç”ŸæˆåŸºç¡€è¡ŒåŠ¨æç¤º"""
    if mdd_recent_month >= HIGH_ELASTICITY_MIN_DRAWDOWN and max_drop_days_week == 1:
        if pd.isna(rsi_val): return 'é«˜å›æ’¤è§‚å¯Ÿ (RSIæ•°æ®ç¼ºå¤±)'
        
        # P1 æå€¼è¶…å–
        if rsi_val <= EXTREME_RSI_THRESHOLD_P1:
            return f'ğŸŒŸ P1-æå€¼è¶…å– (RSI<={EXTREME_RSI_THRESHOLD_P1:.0f})'
        # P2 å¼ºåŠ›è¶…å–
        elif rsi_val <= STRONG_RSI_THRESHOLD_P2:
            return f'ğŸ”¥ P2-å¼ºåŠ›è¶…å– (RSI<={STRONG_RSI_THRESHOLD_P2:.0f})'
        else:
            return 'è§‚å¯Ÿä¸­ (RSIæœªè¶…å–)'
    else:
        return 'ä¸é€‚ç”¨ (éé«˜å¼¹æ€§ç²¾é€‰)'

def analyze_single_fund(filepath):
    """åˆ†æå•åªåŸºé‡‘"""
    try:
        fund_code = os.path.splitext(os.path.basename(filepath))[0]
        df = pd.read_csv(filepath)
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values(by='date', ascending=False).reset_index(drop=True)
        df = df.rename(columns={'net_value': 'value'})
        is_valid, msg = validate_fund_data(df, fund_code)
        if not is_valid: return None
        
        df_recent_month = df.head(30)
        df_recent_week = df.head(5)
        mdd_recent_month = calculate_max_drawdown(df_recent_month['value'])
        max_drop_days_week = calculate_consecutive_drops(df_recent_week['value'])
        tech_indicators = calculate_technical_indicators(df)
        
        action_prompt = get_action_prompt(
            tech_indicators.get('RSI', np.nan), 
            tech_indicators.get('å½“æ—¥è·Œå¹…', 0.0), 
            mdd_recent_month, 
            max_drop_days_week
        )
        
        if mdd_recent_month >= MIN_MONTH_DRAWDOWN:
            return {
                'åŸºé‡‘ä»£ç ': fund_code,
                'æœ€å¤§å›æ’¤': mdd_recent_month,
                'æœ€å¤§è¿ç»­ä¸‹è·Œ': calculate_consecutive_drops(df_recent_month['value']),
                'è¿‘ä¸€å‘¨è¿è·Œ': max_drop_days_week,
                **tech_indicators,
                'è¡ŒåŠ¨æç¤º': action_prompt
            }
        return None
    except Exception as e:
        logging.error(f"åˆ†æåŸºé‡‘ {filepath} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None

def analyze_all_funds(target_codes=None):
    """åˆ†ææ‰€æœ‰åŸºé‡‘æ•°æ®"""
    try:
        if target_codes:
            csv_files = [os.path.join(FUND_DATA_DIR, f'{code}.csv') for code in target_codes if os.path.exists(os.path.join(FUND_DATA_DIR, f'{code}.csv'))]
        else:
            csv_files = glob.glob(os.path.join(FUND_DATA_DIR, '*.csv'))
        
        if not csv_files:
            logging.warning(f"åœ¨ç›®å½• '{FUND_DATA_DIR}' ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶")
            return []
        
        logging.info(f"æ‰¾åˆ° {len(csv_files)} ä¸ªåŸºé‡‘æ•°æ®æ–‡ä»¶ï¼Œå¼€å§‹åˆ†æ...")
        qualifying_funds = []
        for filepath in csv_files:
            result = analyze_single_fund(filepath)
            if result is not None:
                qualifying_funds.append(result)
        
        logging.info(f"åˆ†æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(qualifying_funds)} åªç¬¦åˆåŸºç¡€é¢„è­¦æ¡ä»¶çš„åŸºé‡‘")
        return qualifying_funds
    except Exception as e:
        logging.error(f"åˆ†ææ‰€æœ‰åŸºé‡‘æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return []

def format_technical_value(value, format_type='percent'):
    """æ ¼å¼åŒ–æŠ€æœ¯æŒ‡æ ‡å€¼ç”¨äºæ˜¾ç¤º"""
    if pd.isna(value): return 'NaN'
    if format_type == 'percent': return f"{value:.2%}"
    elif format_type == 'decimal2': return f"{value:.2f}"
    elif format_type == 'decimal4': return f"{value:.4f}"
    else: return str(value)

def format_table_row(index, row):
    """æ ¼å¼åŒ– Markdown è¡¨æ ¼è¡Œï¼ŒåŒ…å«é¢œè‰²/ç¬¦å·æ ‡è®°"""
    latest_value = row.get('æœ€æ–°å‡€å€¼', 1.0)
    trial_price = latest_value * 0.97 
    trend_display = row['MA50/MA250è¶‹åŠ¿']
    ma_ratio_display = format_technical_value(row['MA50/MA250'], 'decimal2')
    
    # è¶‹åŠ¿é£é™©è­¦å‘Š
    if trend_display == 'å‘ä¸‹' and row['MA50/MA250'] < 0.95:
         trend_display = f"âš ï¸ {trend_display}"
         ma_ratio_display = f"âš ï¸ {ma_ratio_display}"

    return (
        f"| {index} | `{row['åŸºé‡‘ä»£ç ']}` | **{format_technical_value(row['æœ€å¤§å›æ’¤'], 'percent')}** | "
        f"{format_technical_value(row['å½“æ—¥è·Œå¹…'], 'percent')} | {row['RSI']:.2f} | "
        f"{row['MACDä¿¡å·']} | {row['å¸ƒæ—å¸¦ä½ç½®']} | {format_technical_value(row['å‡€å€¼/MA50'], 'decimal2')} | "
        f"**{ma_ratio_display}** | **{trend_display}** | "
        f"{format_technical_value(row['å‡€å€¼/MA250'], 'decimal2')} | {trial_price:.4f} | **{row['è¡ŒåŠ¨æç¤º']}** |\n"
    )

def generate_report(results, timestamp_str):
    """
    ç”Ÿæˆå®Œæ•´çš„Markdownæ ¼å¼æŠ¥å‘Š
    """
    try:
        if not results:
            return (f"# åŸºé‡‘é¢„è­¦æŠ¥å‘Š ({timestamp_str} UTC+8)\n\n"
                    f"**æ­å–œï¼Œæ²¡æœ‰å‘ç°æ»¡è¶³åŸºç¡€é¢„è­¦æ¡ä»¶çš„åŸºé‡‘ã€‚**")

        df_results = pd.DataFrame(results).sort_values(by='æœ€å¤§å›æ’¤', ascending=False).reset_index(drop=True)
        # æ ¸å¿ƒä¿®å¤ç‚¹ï¼šä½¿ç”¨ len(results) ä½œä¸ºå‡†ç¡®çš„æ€»æ•°
        actual_total_count = len(results)

        report_parts = []
        report_parts.extend([
            f"# åŸºé‡‘é¢„è­¦æŠ¥å‘Š ({timestamp_str} UTC+8)\n\n",
            f"## åˆ†ææ€»ç»“\n\n",
            f"æœ¬æ¬¡åˆ†æå…±å‘ç° **{actual_total_count}** åªåŸºé‡‘æ»¡è¶³åŸºç¡€é¢„è­¦æ¡ä»¶ï¼ˆè¿‘ 1 ä¸ªæœˆå›æ’¤ $\\ge {MIN_MONTH_DRAWDOWN*100:.0f}\\%$ï¼‰ã€‚\n",
            f"**ç­–ç•¥æ›´æ–°ï¼šRSIç¬¬ä¸€ä¼˜å…ˆçº§é˜ˆå€¼ $\\le {EXTREME_RSI_THRESHOLD_P1:.0f}$ï¼›ç¬¬äºŒä¼˜å…ˆçº§é˜ˆå€¼ $\\le {STRONG_RSI_THRESHOLD_P2:.0f}$ã€‚**\n",
            f"---\n"
        ])

        # æ ¸å¿ƒç­›é€‰ï¼šé«˜å¼¹æ€§åŸºé‡‘ (MDD>=10% ä¸” è¿‘ä¸€å‘¨è¿è·Œ=1)
        df_base_elastic = df_results[
            (df_results['æœ€å¤§å›æ’¤'] >= HIGH_ELASTICITY_MIN_DRAWDOWN) &
            (df_results['è¿‘ä¸€å‘¨è¿è·Œ'] == 1)
        ].copy()

        # å¼•å…¥æ•´æ•°æ¯”è¾ƒåˆ—ï¼Œç¡®ä¿å½“æ—¥è·Œå¹…ç­›é€‰å‡†ç¡®æ€§
        CRITICAL_DROP_INT = int(MIN_DAILY_DROP_PERCENT * 1000)
        df_base_elastic['å½“æ—¥è·Œå¹…_INT'] = (df_base_elastic['å½“æ—¥è·Œå¹…'] * 1000).astype(int)

        # ----------------------------------------------------
        # 1. ğŸ¥‡ ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šRSI <= 29.0
        # ----------------------------------------------------
        df_p1 = df_base_elastic[
            df_base_elastic['RSI'] <= EXTREME_RSI_THRESHOLD_P1
        ].copy()

        # 1.1 P1Aï¼šã€å³æ—¶ææ…Œä¹°å…¥ã€‘(RSI <= 29 ä¸” å½“æ—¥å¤§è·Œ >= 3%)
        df_p1a = df_p1[
            df_p1['å½“æ—¥è·Œå¹…_INT'] >= CRITICAL_DROP_INT 
        ].copy()

        # 1.2 P1Bï¼šã€æŠ€æœ¯å…±æŒ¯å»ºä»“ã€‘(RSI <= 29 ä¸” å½“æ—¥è·Œå¹… < 3%)
        df_p1b = df_p1[
            df_p1['å½“æ—¥è·Œå¹…_INT'] < CRITICAL_DROP_INT 
        ].copy()
        
        # --- æŠ¥å‘Š P1A ---
        if not df_p1a.empty:
            df_p1a = df_p1a.sort_values(by=['å½“æ—¥è·Œå¹…', 'RSI'], ascending=[False, True]).reset_index(drop=True)
            df_p1a.index = df_p1a.index + 1
            
            report_parts.extend([
                f"\n## **ğŸ¥‡ ç¬¬ä¸€ä¼˜å…ˆçº§ Aï¼šã€å³æ—¶ææ…Œä¹°å…¥ã€‘** ({len(df_p1a)}åª)\n\n",
                f"**æ¡ä»¶ï¼š** é•¿æœŸè¶…è·Œ + **RSIæåº¦è¶…å– ($\\le {EXTREME_RSI_THRESHOLD_P1:.0f}$)** + **å½“æ—¥è·Œå¹… $\\ge$ {MIN_DAILY_DROP_PERCENT*100:.0f}%**\n",
                r"**çºªå¾‹ï¼š** å¸‚åœºææ…Œæ—¶å‡ºæ‰‹ï¼Œæœ¬é‡‘å……è¶³æ—¶åº”ä¼˜å…ˆé…ç½®ã€‚**ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰**" + "\n\n",
                f"| æ’å | åŸºé‡‘ä»£ç  | æœ€å¤§å›æ’¤ (1M) | **å½“æ—¥è·Œå¹…** | RSI(14) | MACDä¿¡å· | å¸ƒæ—å¸¦ä½ç½® | å‡€å€¼/MA50 | **MA50/MA250** | **è¶‹åŠ¿** | å‡€å€¼/MA250 | è¯•æ°´ä¹°ä»· (è·Œ3%) | è¡ŒåŠ¨æç¤º |\n",
                f"| :---: | :---: | ---: | ---: | ---: | :---: | :---: | ---: | **---:** | :---: | ---: | :---: | :---: |\n"
            ])
            for index, row in df_p1a.iterrows():
                report_parts.append(format_table_row(index, row))
            report_parts.append("\n---\n")

        # --- æŠ¥å‘Š P1B ---
        if not df_p1b.empty:
            df_p1b = df_p1b.sort_values(by=['RSI', 'æœ€å¤§å›æ’¤'], ascending=[True, False]).reset_index(drop=True)
            df_p1b.index = df_p1b.index + 1
            
            report_parts.extend([
                f"\n## **ğŸ¥‡ ç¬¬ä¸€ä¼˜å…ˆçº§ Bï¼šã€æŠ€æœ¯å…±æŒ¯å»ºä»“ã€‘** ({len(df_p1b)}åª)\n\n",
                f"**æ¡ä»¶ï¼š** é•¿æœŸè¶…è·Œ + **RSIæåº¦è¶…å– ($\\le {EXTREME_RSI_THRESHOLD_P1:.0f}$)** + **å½“æ—¥è·Œå¹… $\\lt$ {MIN_DAILY_DROP_PERCENT*100:.0f}%**\n",
                r"**çºªå¾‹ï¼š** æå€¼è¶…å–ï¼Œé€‚åˆåœ¨éå¤§è·Œæ—¥è¿›è¡Œå»ºä»“ã€‚**ï¼ˆç¬¬äºŒé«˜ä¼˜å…ˆçº§ï¼‰**" + "\n\n",
                f"| æ’å | åŸºé‡‘ä»£ç  | æœ€å¤§å›æ’¤ (1M) | **å½“æ—¥è·Œå¹…** | RSI(14) | MACDä¿¡å· | å¸ƒæ—å¸¦ä½ç½® | å‡€å€¼/MA50 | **MA50/MA250** | **è¶‹åŠ¿** | å‡€å€¼/MA250 | è¯•æ°´ä¹°ä»· (è·Œ3%) | è¡ŒåŠ¨æç¤º |\n",
                f"| :---: | :---: | ---: | ---: | ---: | :---: | :---: | ---: | **---:** | :---: | ---: | :---: | :---: |\n"
            ])
            for index, row in df_p1b.iterrows():
                report_parts.append(format_table_row(index, row))
            report_parts.append("\n---\n")

        # ----------------------------------------------------
        # 2. ğŸ¥ˆ ç¬¬äºŒä¼˜å…ˆçº§ï¼š29.0 < RSI <= 35.0
        # ----------------------------------------------------
        
        # ç­›é€‰å‡ºæ»¡è¶³å¼ºåŠ›è¶…å–ä½†æœªè¿›å…¥æå€¼åŒºçš„åŸºé‡‘
        df_p2 = df_base_elastic[
            (df_base_elastic['RSI'] > EXTREME_RSI_THRESHOLD_P1) &
            (df_base_elastic['RSI'] <= STRONG_RSI_THRESHOLD_P2)
        ].copy()

        if not df_p2.empty:
            df_p2 = df_p2.sort_values(by=['RSI', 'æœ€å¤§å›æ’¤'], ascending=[True, False]).reset_index(drop=True)
            df_p2.index = df_p2.index + 1
            
            report_parts.extend([
                f"\n## **ğŸ¥ˆ ç¬¬äºŒä¼˜å…ˆçº§ï¼šã€å¼ºåŠ›è¶…å–è§‚å¯Ÿæ± ã€‘** ({len(df_p2)}åª)\n\n",
                f"**æ¡ä»¶ï¼š** é•¿æœŸè¶…è·Œ + **å¼ºåŠ›è¶…å– ($>{EXTREME_RSI_THRESHOLD_P1:.0f}$ ä¸” $\\le {STRONG_RSI_THRESHOLD_P2:.0f}$)**ã€‚\n",
                r"**çºªå¾‹ï¼š** æ¥è¿‘æå€¼ï¼Œæ˜¯è‰¯å¥½çš„è§‚å¯Ÿç›®æ ‡ï¼Œä½†éœ€ç­‰å¾… RSI è¿›ä¸€æ­¥ä¸‹è¡Œæˆ–è¶‹åŠ¿ç¡®ç«‹ã€‚**ï¼ˆç¬¬ä¸‰ä¼˜å…ˆçº§ï¼‰**" + "\n\n",
                f"| æ’å | åŸºé‡‘ä»£ç  | æœ€å¤§å›æ’¤ (1M) | **å½“æ—¥è·Œå¹…** | RSI(14) | MACDä¿¡å· | å¸ƒæ—å¸¦ä½ç½® | å‡€å€¼/MA50 | **MA50/MA250** | **è¶‹åŠ¿** | å‡€å€¼/MA250 | è¯•æ°´ä¹°ä»· (è·Œ3%) | è¡ŒåŠ¨æç¤º |\n",
                f"| :---: | :---: | ---: | ---: | ---: | :---: | :---: | ---: | :---: | **---:** | :---: | ---: | :---: | :---: |\n"
            ])

            for index, row in df_p2.iterrows():
                report_parts.append(format_table_row(index, row))
            report_parts.append("\n---\n")
        else:
            report_parts.extend([
                f"\n## **ğŸ¥ˆ ç¬¬äºŒä¼˜å…ˆçº§ï¼šã€å¼ºåŠ›è¶…å–è§‚å¯Ÿæ± ã€‘**\n\n",
                f"æ²¡æœ‰åŸºé‡‘æ»¡è¶³ **é•¿æœŸè¶…è·Œ** ä¸” **RSI ($>{EXTREME_RSI_THRESHOLD_P1:.0f}$ ä¸” $\\le {STRONG_RSI_THRESHOLD_P2:.0f}$)** çš„æ¡ä»¶ã€‚" + "\n\n",
                f"---\n"
            ])


        # 3. ğŸ¥‰ ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šæ‰©å±•è§‚å¯Ÿæ±  (RSI > 35.0)
        df_p3 = df_base_elastic[
            df_base_elastic['RSI'] > STRONG_RSI_THRESHOLD_P2
        ].copy()

        if not df_p3.empty:
            df_p3 = df_p3.sort_values(by='æœ€å¤§å›æ’¤', ascending=False).reset_index(drop=True)
            df_p3.index = df_p3.index + 1

            report_parts.extend([
                f"\n## **ğŸ¥‰ ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šã€æ‰©å±•è§‚å¯Ÿæ± ã€‘** ({len(df_p3)}åª)\n\n",
                f"**æ¡ä»¶ï¼š** é•¿æœŸè¶…è·Œ + **RSI $>{STRONG_RSI_THRESHOLD_P2:.0f}$ (æœªè¾¾å¼ºåŠ›è¶…å–)**ã€‚\n",
                r"**çºªå¾‹ï¼š** é£é™©è¾ƒé«˜ï¼Œä»…ä½œä¸ºè§‚å¯Ÿå’Œå¤‡é€‰ï¼Œç­‰å¾… RSI è¿›ä¸€æ­¥è¿›å…¥è¶…å–åŒºã€‚**ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰**" + "\n\n",
                f"| æ’å | åŸºé‡‘ä»£ç  | æœ€å¤§å›æ’¤ (1M) | **å½“æ—¥è·Œå¹…** | RSI(14) | MACDä¿¡å· | å¸ƒæ—å¸¦ä½ç½® | å‡€å€¼/MA50 | **MA50/MA250** | **è¶‹åŠ¿** | å‡€å€¼/MA250 | è¯•æ°´ä¹°ä»· (è·Œ3%) | è¡ŒåŠ¨æç¤º |\n",
                f"| :---: | :---: | ---: | ---: | ---: | :---: | ---: | :---: | **---:** | :---: | ---: | :---: | :---: |\n"
            ])

            for index, row in df_p3.iterrows():
                report_parts.append(format_table_row(index, row))
            report_parts.append("\n---\n")
        
        # ç­–ç•¥æ‰§è¡Œçºªå¾‹ï¼ˆåŒ…å«è¡Œä¸šé£é™©æç¤ºï¼‰
        report_parts.extend([
            "\n---\n",
            f"## **âš ï¸ å¼ºåŒ–æ‰§è¡Œçºªå¾‹ï¼šé£æ§ä¸è¡Œä¸šå®¡æŸ¥**\n\n",
            f"**1. ğŸ›‘ è¶‹åŠ¿å¥åº·åº¦ï¼ˆMA50/MA250 å†³å®šèƒ½å¦ä¹°ï¼‰ï¼š**\n",
            r"    * **MA50/MA250 $\\ge 0.95$ ä¸” è¶‹åŠ¿æ–¹å‘ä¸º 'å‘ä¸Š' æˆ– 'å¹³ç¨³'** çš„åŸºé‡‘ï¼Œè§†ä¸º **è¶‹åŠ¿å¥åº·**ï¼Œå…è®¸è¯•æ°´ã€‚", "\n",
            r"    * **è‹¥åŸºé‡‘è¶‹åŠ¿æ˜¾ç¤º âš ï¸ å‘ä¸‹ï¼Œæˆ– MA50/MA250 $< 0.95$ï¼Œ** åˆ™è¡¨æ˜é•¿æœŸå¤„äºç†Šå¸‚é€šé“ï¼Œ**å¿…é¡»æ”¾å¼ƒ**ï¼Œæ— è®ºçŸ­æœŸè¶…è·Œæœ‰å¤šä¸¥é‡ã€‚", "\n",
            f"**2. ğŸ” äººå·¥è¡Œä¸šä¸Kçº¿å®¡æŸ¥ï¼ˆæ’é™¤æ¥é£åˆ€é£é™©ï¼‰ï¼š**\n",
            r"    * **åœ¨ä¹°å…¥å‰ï¼Œå¿…é¡»æŸ¥é˜…åŸºé‡‘é‡ä»“è¡Œä¸šã€‚** å¦‚æœåŸºé‡‘å±äºè¿‘æœŸï¼ˆå¦‚è¿‘ 3-6 ä¸ªæœˆï¼‰**æ¶¨å¹…å·¨å¤§ã€ä¼°å€¼è¿‡é«˜**çš„æ¿å—ï¼ˆä¾‹å¦‚ï¼šéƒ¨åˆ†AIã€åŠå¯¼ä½“ï¼‰ï¼Œåˆ™å³ä½¿æŠ€æœ¯è¶…å–ï¼Œä¹Ÿåº”è§†ä¸º**é«˜é£é™©å›è°ƒ**ï¼Œå»ºè®®**æ”¾å¼ƒ**æˆ–**å¤§å¹…ç¼©å‡**è¯•æ°´ä»“ä½ã€‚", "\n",
            r"    * **åŒæ—¶å¤æ ¸ K çº¿å›¾ï¼š** ç¡®è®¤å½“å‰ä»·æ ¼æ˜¯å¦è·ç¦»**è¿‘åŠå¹´å†å²é«˜ç‚¹**å¤ªè¿‘ã€‚è‹¥æ˜¯ï¼Œåˆ™é£é™©é«˜ã€‚", "\n",
            f"**3. I çº§è¯•æ°´å»ºä»“ï¼ˆRSIæå€¼ç­–ç•¥ï¼‰ï¼š**\n",
            r"    * ä»…å½“åŸºé‡‘æ»¡è¶³ï¼š**è¶‹åŠ¿å¥åº·** + **å‡€å€¼/MA50 $\\le 1.0$** + **RSI $\\le {EXTREME_RSI_THRESHOLD_P1:.0f}$** æ—¶ï¼Œæ‰è¿›è¡Œ $\mathbf{I}$ çº§è¯•æ°´ã€‚", "\n",
            f"**4. é£é™©æ§åˆ¶ï¼š**\n",
            f"    * ä¸¥æ ¼æ­¢æŸçº¿ï¼šå¹³å‡æˆæœ¬ä»·**è·Œå¹…è¾¾åˆ° 8%-10%**ï¼Œç«‹å³æ¸…ä»“æ­¢æŸã€‚\n"
        ])

        return "".join(report_parts)
        
    except Exception as e:
        logging.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return f"# æŠ¥å‘Šç”Ÿæˆé”™è¯¯\n\né”™è¯¯ä¿¡æ¯: {str(e)}"

def main():
    """ä¸»å‡½æ•°"""
    try:
        setup_logging()
        try:
            tz = pytz.timezone('Asia/Shanghai')
            now = datetime.now(tz)
        except:
            now = datetime.now()
            logging.warning("ä½¿ç”¨æ—¶åŒºå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ—¶é—´")
        
        timestamp_for_report = now.strftime('%Y-%m-%d %H:%M:%S')
        timestamp_for_filename = now.strftime('%Y%m%d_%H%M%S')
        dir_name = now.strftime('%Y%m')

        os.makedirs(dir_name, exist_ok=True)
        report_file = os.path.join(dir_name, f"{REPORT_BASE_NAME}_{timestamp_for_filename}.md")

        logging.info("å¼€å§‹åˆ†æåŸºé‡‘æ•°æ®...")
        
        results = analyze_all_funds()
        
        report_content = generate_report(results, timestamp_for_report)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logging.info(f"åˆ†æå®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜åˆ° {report_file}")
        return True
        
    except Exception as e:
        logging.error(f"ä¸»ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return False

if __name__ == '__main__':
    # è¯·ç¡®ä¿ 'fund_data' ç›®å½•å­˜åœ¨ï¼Œä¸”å…¶ä¸­åŒ…å«ä»¥åŸºé‡‘ä»£ç å‘½åçš„ CSV æ–‡ä»¶ (date, net_value)
    success = main()
    print("è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚è¯·æ£€æŸ¥è¾“å‡ºçš„æŠ¥å‘Šæ–‡ä»¶ï¼Œå¹¶éªŒè¯åŠŸèƒ½æ˜¯å¦ç¬¦åˆé¢„æœŸã€‚")
